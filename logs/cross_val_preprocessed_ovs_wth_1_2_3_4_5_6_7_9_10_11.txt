INFO:root:the deviced being used is cuda:0
INFO:root:Start validation
INFO:root:statistics used: {'mean': tensor([0.1729, 0.1692]), 'std': tensor([0.0638, 0.0625])}
INFO:root:train dataset: 131886, test dataset: 6256
INFO:root:used only channels: [0, 8]; only classes: None
INFO:root:epoch0
INFO:root:[1,    50] training loss: 0.04569592
INFO:root:[1,   100] training loss: 0.04450718
INFO:root:[1,   150] training loss: 0.05665896
INFO:root:[1,   200] training loss: 0.05850965
INFO:root:[1,   250] training loss: 0.05155894
INFO:root:[1,   300] training loss: 0.06010388
INFO:root:[1,   350] training loss: 0.04873203
INFO:root:[1,   400] training loss: 0.05920381
INFO:root:epoch1
INFO:root:[2,    50] training loss: 0.03527157
INFO:root:[2,   100] training loss: 0.03791318
INFO:root:[2,   150] training loss: 0.04811019
INFO:root:[2,   200] training loss: 0.05062225
INFO:root:[2,   250] training loss: 0.04581451
INFO:root:[2,   300] training loss: 0.05013814
INFO:root:[2,   350] training loss: 0.04554999
INFO:root:[2,   400] training loss: 0.05238119
INFO:root:epoch2
INFO:root:[3,    50] training loss: 0.04032602
INFO:root:[3,   100] training loss: 0.03642610
INFO:root:[3,   150] training loss: 0.04685251
INFO:root:[3,   200] training loss: 0.05291526
INFO:root:[3,   250] training loss: 0.05112399
INFO:root:[3,   300] training loss: 0.05457197
INFO:root:[3,   350] training loss: 0.05515687
INFO:root:[3,   400] training loss: 0.05558111
INFO:root:epoch3
INFO:root:[4,    50] training loss: 0.03591553
INFO:root:[4,   100] training loss: 0.03458814
INFO:root:[4,   150] training loss: 0.04857131
INFO:root:[4,   200] training loss: 0.05266002
INFO:root:[4,   250] training loss: 0.05062324
INFO:root:[4,   300] training loss: 0.05474222
INFO:root:[4,   350] training loss: 0.05559177
INFO:root:[4,   400] training loss: 0.05364596
INFO:root:epoch4
INFO:root:[5,    50] training loss: 0.03445011
INFO:root:[5,   100] training loss: 0.03257646
INFO:root:[5,   150] training loss: 0.04806187
INFO:root:[5,   200] training loss: 0.05079904
INFO:root:[5,   250] training loss: 0.04816251
INFO:root:[5,   300] training loss: 0.04927134
INFO:root:[5,   350] training loss: 0.05205094
INFO:root:[5,   400] training loss: 0.04993812
INFO:root:epoch5
INFO:root:[6,    50] training loss: 0.03336227
INFO:root:[6,   100] training loss: 0.02993846
INFO:root:[6,   150] training loss: 0.04441896
INFO:root:[6,   200] training loss: 0.05028330
INFO:root:[6,   250] training loss: 0.04945472
INFO:root:[6,   300] training loss: 0.04949416
INFO:root:[6,   350] training loss: 0.05057847
INFO:root:[6,   400] training loss: 0.04668238
INFO:root:epoch6
INFO:root:[7,    50] training loss: 0.03053936
INFO:root:[7,   100] training loss: 0.02951145
INFO:root:[7,   150] training loss: 0.04504191
INFO:root:[7,   200] training loss: 0.04977911
INFO:root:[7,   250] training loss: 0.04683606
INFO:root:[7,   300] training loss: 0.04485383
INFO:root:[7,   350] training loss: 0.04647562
INFO:root:[7,   400] training loss: 0.04352396
INFO:root:epoch7
INFO:root:[8,    50] training loss: 0.04870439
INFO:root:[8,   100] training loss: 0.04335317
INFO:root:[8,   150] training loss: 0.06321529
INFO:root:[8,   200] training loss: 0.05871873
INFO:root:[8,   250] training loss: 0.05345720
INFO:root:[8,   300] training loss: 0.04980659
INFO:root:[8,   350] training loss: 0.05008862
INFO:root:[8,   400] training loss: 0.03789837
INFO:root:epoch8
INFO:root:[9,    50] training loss: 0.02799904
INFO:root:[9,   100] training loss: 0.03434825
INFO:root:[9,   150] training loss: 0.05975153
INFO:root:[9,   200] training loss: 0.05676378
INFO:root:[9,   250] training loss: 0.05108511
INFO:root:[9,   300] training loss: 0.04890735
INFO:root:[9,   350] training loss: 0.04936453
INFO:root:[9,   400] training loss: 0.03838335
INFO:root:epoch9
INFO:root:[10,    50] training loss: 0.02361684
INFO:root:[10,   100] training loss: 0.03235338
INFO:root:[10,   150] training loss: 0.05872616
INFO:root:[10,   200] training loss: 0.05544750
INFO:root:[10,   250] training loss: 0.04898609
INFO:root:[10,   300] training loss: 0.04804659
INFO:root:[10,   350] training loss: 0.04885045
INFO:root:[10,   400] training loss: 0.03922807
INFO:root:epoch10
INFO:root:[11,    50] training loss: 0.02145819
INFO:root:[11,   100] training loss: 0.03143265
INFO:root:[11,   150] training loss: 0.05769686
INFO:root:[11,   200] training loss: 0.05438180
INFO:root:[11,   250] training loss: 0.04679870
INFO:root:[11,   300] training loss: 0.04738451
INFO:root:[11,   350] training loss: 0.04850518
INFO:root:[11,   400] training loss: 0.03962767
INFO:root:epoch11
INFO:root:[12,    50] training loss: 0.02037922
INFO:root:[12,   100] training loss: 0.03075159
INFO:root:[12,   150] training loss: 0.05693182
INFO:root:[12,   200] training loss: 0.05320383
INFO:root:[12,   250] training loss: 0.04502512
INFO:root:[12,   300] training loss: 0.04664473
INFO:root:[12,   350] training loss: 0.04813226
INFO:root:[12,   400] training loss: 0.04021665
INFO:root:epoch12
INFO:root:[13,    50] training loss: 0.01938662
INFO:root:[13,   100] training loss: 0.03021807
INFO:root:[13,   150] training loss: 0.05605028
INFO:root:[13,   200] training loss: 0.05193325
INFO:root:[13,   250] training loss: 0.04352546
INFO:root:[13,   300] training loss: 0.04626154
INFO:root:[13,   350] training loss: 0.04802334
INFO:root:[13,   400] training loss: 0.04089353
INFO:root:epoch13
INFO:root:[14,    50] training loss: 0.01891307
INFO:root:[14,   100] training loss: 0.02977243
INFO:root:[14,   150] training loss: 0.05518592
INFO:root:[14,   200] training loss: 0.05058816
INFO:root:[14,   250] training loss: 0.04182223
INFO:root:[14,   300] training loss: 0.04578913
INFO:root:[14,   350] training loss: 0.04786030
INFO:root:[14,   400] training loss: 0.04114421
INFO:root:epoch14
INFO:root:[15,    50] training loss: 0.01879698
INFO:root:[15,   100] training loss: 0.03030850
INFO:root:[15,   150] training loss: 0.05678695
INFO:root:[15,   200] training loss: 0.05302689
INFO:root:[15,   250] training loss: 0.04253927
INFO:root:[15,   300] training loss: 0.04626256
INFO:root:[15,   350] training loss: 0.04607664
INFO:root:[15,   400] training loss: 0.03626679
INFO:root:epoch15
INFO:root:[16,    50] training loss: 0.01858452
INFO:root:[16,   100] training loss: 0.02981052
INFO:root:[16,   150] training loss: 0.05645039
INFO:root:[16,   200] training loss: 0.05253895
INFO:root:[16,   250] training loss: 0.04157123
INFO:root:[16,   300] training loss: 0.04588886
INFO:root:[16,   350] training loss: 0.04618044
INFO:root:[16,   400] training loss: 0.03700097
INFO:root:epoch16
INFO:root:[17,    50] training loss: 0.01836745
INFO:root:[17,   100] training loss: 0.02956595
INFO:root:[17,   150] training loss: 0.05595158
INFO:root:[17,   200] training loss: 0.05236342
INFO:root:[17,   250] training loss: 0.04114036
INFO:root:[17,   300] training loss: 0.04544480
INFO:root:[17,   350] training loss: 0.04622436
INFO:root:[17,   400] training loss: 0.03731541
INFO:root:epoch17
INFO:root:[18,    50] training loss: 0.01818814
INFO:root:[18,   100] training loss: 0.02934297
INFO:root:[18,   150] training loss: 0.05561971
INFO:root:[18,   200] training loss: 0.05198421
INFO:root:[18,   250] training loss: 0.04052719
INFO:root:[18,   300] training loss: 0.04516672
INFO:root:[18,   350] training loss: 0.04648231
INFO:root:[18,   400] training loss: 0.03758300
INFO:root:epoch18
INFO:root:[19,    50] training loss: 0.01817411
INFO:root:[19,   100] training loss: 0.02913249
INFO:root:[19,   150] training loss: 0.05529657
INFO:root:[19,   200] training loss: 0.05162720
INFO:root:[19,   250] training loss: 0.04013985
INFO:root:[19,   300] training loss: 0.04519776
INFO:root:[19,   350] training loss: 0.04642180
INFO:root:[19,   400] training loss: 0.03787639
INFO:root:epoch19
INFO:root:[20,    50] training loss: 0.01804366
INFO:root:[20,   100] training loss: 0.02902209
INFO:root:[20,   150] training loss: 0.05495777
INFO:root:[20,   200] training loss: 0.05127116
INFO:root:[20,   250] training loss: 0.03955779
INFO:root:[20,   300] training loss: 0.04492966
INFO:root:[20,   350] training loss: 0.04639427
INFO:root:[20,   400] training loss: 0.03825869
INFO:root:epoch20
INFO:root:[21,    50] training loss: 0.01797905
INFO:root:[21,   100] training loss: 0.02889487
INFO:root:[21,   150] training loss: 0.05465704
INFO:root:[21,   200] training loss: 0.05107947
INFO:root:[21,   250] training loss: 0.03950599
INFO:root:[21,   300] training loss: 0.04510614
INFO:root:[21,   350] training loss: 0.04650694
INFO:root:[21,   400] training loss: 0.03846866
INFO:root:epoch21
INFO:root:[22,    50] training loss: 0.01797646
INFO:root:[22,   100] training loss: 0.02896148
INFO:root:[22,   150] training loss: 0.05463663
INFO:root:[22,   200] training loss: 0.05137594
INFO:root:[22,   250] training loss: 0.03911203
INFO:root:[22,   300] training loss: 0.04464040
INFO:root:[22,   350] training loss: 0.04622173
INFO:root:[22,   400] training loss: 0.03774382
INFO:root:epoch22
INFO:root:[23,    50] training loss: 0.01794451
INFO:root:[23,   100] training loss: 0.02898545
INFO:root:[23,   150] training loss: 0.05469371
INFO:root:[23,   200] training loss: 0.05127511
INFO:root:[23,   250] training loss: 0.03939608
INFO:root:[23,   300] training loss: 0.04445136
INFO:root:[23,   350] training loss: 0.04620714
INFO:root:[23,   400] training loss: 0.03772508
INFO:root:epoch23
INFO:root:[24,    50] training loss: 0.01781968
INFO:root:[24,   100] training loss: 0.02893338
INFO:root:[24,   150] training loss: 0.05463175
INFO:root:[24,   200] training loss: 0.05136467
INFO:root:[24,   250] training loss: 0.03921804
INFO:root:[24,   300] training loss: 0.04455650
INFO:root:[24,   350] training loss: 0.04636422
INFO:root:[24,   400] training loss: 0.03781380
INFO:root:epoch24
INFO:root:[25,    50] training loss: 0.01789994
INFO:root:[25,   100] training loss: 0.02891705
INFO:root:[25,   150] training loss: 0.05454103
INFO:root:[25,   200] training loss: 0.05113424
INFO:root:[25,   250] training loss: 0.03905022
INFO:root:[25,   300] training loss: 0.04475801
INFO:root:[25,   350] training loss: 0.04619073
INFO:root:[25,   400] training loss: 0.03793866
INFO:root:epoch25
INFO:root:[26,    50] training loss: 0.01793401
INFO:root:[26,   100] training loss: 0.02884338
INFO:root:[26,   150] training loss: 0.05459153
INFO:root:[26,   200] training loss: 0.05099105
INFO:root:[26,   250] training loss: 0.03921537
INFO:root:[26,   300] training loss: 0.04448860
INFO:root:[26,   350] training loss: 0.04614636
INFO:root:[26,   400] training loss: 0.03800979
INFO:root:epoch26
INFO:root:[27,    50] training loss: 0.01796010
INFO:root:[27,   100] training loss: 0.02878527
INFO:root:[27,   150] training loss: 0.05454883
INFO:root:[27,   200] training loss: 0.05104497
INFO:root:[27,   250] training loss: 0.03894774
INFO:root:[27,   300] training loss: 0.04469358
INFO:root:[27,   350] training loss: 0.04624882
INFO:root:[27,   400] training loss: 0.03791875
INFO:root:epoch27
INFO:root:[28,    50] training loss: 0.01787357
INFO:root:[28,   100] training loss: 0.02874107
INFO:root:[28,   150] training loss: 0.05461102
INFO:root:[28,   200] training loss: 0.05100846
INFO:root:[28,   250] training loss: 0.03912614
INFO:root:[28,   300] training loss: 0.04460234
INFO:root:[28,   350] training loss: 0.04624843
INFO:root:[28,   400] training loss: 0.03788523
INFO:root:epoch28
INFO:root:[29,    50] training loss: 0.01801474
INFO:root:[29,   100] training loss: 0.02880852
INFO:root:[29,   150] training loss: 0.05448331
INFO:root:[29,   200] training loss: 0.05110495
INFO:root:[29,   250] training loss: 0.03911776
INFO:root:[29,   300] training loss: 0.04454522
INFO:root:[29,   350] training loss: 0.04623761
INFO:root:[29,   400] training loss: 0.03777074
INFO:root:epoch29
INFO:root:[30,    50] training loss: 0.01789074
INFO:root:[30,   100] training loss: 0.02877647
INFO:root:[30,   150] training loss: 0.05442861
INFO:root:[30,   200] training loss: 0.05120943
INFO:root:[30,   250] training loss: 0.03920116
INFO:root:[30,   300] training loss: 0.04459511
INFO:root:[30,   350] training loss: 0.04634727
INFO:root:[30,   400] training loss: 0.03784748
INFO:root:epoch30
INFO:root:[31,    50] training loss: 0.01786727
INFO:root:[31,   100] training loss: 0.02880892
INFO:root:[31,   150] training loss: 0.05456387
INFO:root:[31,   200] training loss: 0.05126636
INFO:root:[31,   250] training loss: 0.03896917
INFO:root:[31,   300] training loss: 0.04477366
INFO:root:[31,   350] training loss: 0.04624725
INFO:root:[31,   400] training loss: 0.03784244
INFO:root:epoch31
INFO:root:[32,    50] training loss: 0.01794653
INFO:root:[32,   100] training loss: 0.02869859
INFO:root:[32,   150] training loss: 0.05449893
INFO:root:[32,   200] training loss: 0.05121100
INFO:root:[32,   250] training loss: 0.03910058
INFO:root:[32,   300] training loss: 0.04438077
INFO:root:[32,   350] training loss: 0.04613449
INFO:root:[32,   400] training loss: 0.03785963
INFO:root:epoch32
INFO:root:[33,    50] training loss: 0.01788355
INFO:root:[33,   100] training loss: 0.02881605
INFO:root:[33,   150] training loss: 0.05456828
INFO:root:[33,   200] training loss: 0.05094625
INFO:root:[33,   250] training loss: 0.03917282
INFO:root:[33,   300] training loss: 0.04471079
INFO:root:[33,   350] training loss: 0.04609545
INFO:root:[33,   400] training loss: 0.03776788
INFO:root:epoch33
INFO:root:[34,    50] training loss: 0.01792015
INFO:root:[34,   100] training loss: 0.02889674
INFO:root:[34,   150] training loss: 0.05443274
INFO:root:[34,   200] training loss: 0.05125684
INFO:root:[34,   250] training loss: 0.03898064
INFO:root:[34,   300] training loss: 0.04462847
INFO:root:[34,   350] training loss: 0.04618052
INFO:root:[34,   400] training loss: 0.03809254
INFO:root:epoch34
INFO:root:[35,    50] training loss: 0.01786828
INFO:root:[35,   100] training loss: 0.02885846
INFO:root:[35,   150] training loss: 0.05447631
INFO:root:[35,   200] training loss: 0.05111798
INFO:root:[35,   250] training loss: 0.03897784
INFO:root:[35,   300] training loss: 0.04441141
INFO:root:[35,   350] training loss: 0.04613470
INFO:root:[35,   400] training loss: 0.03769471
INFO:root:epoch35
INFO:root:[36,    50] training loss: 0.01789244
INFO:root:[36,   100] training loss: 0.02879996
INFO:root:[36,   150] training loss: 0.05443469
INFO:root:[36,   200] training loss: 0.05108438
INFO:root:[36,   250] training loss: 0.03873572
INFO:root:[36,   300] training loss: 0.04445075
INFO:root:[36,   350] training loss: 0.04645925
INFO:root:[36,   400] training loss: 0.03794522
INFO:root:epoch36
INFO:root:[37,    50] training loss: 0.01798990
INFO:root:[37,   100] training loss: 0.02880619
INFO:root:[37,   150] training loss: 0.05443254
INFO:root:[37,   200] training loss: 0.05118213
INFO:root:[37,   250] training loss: 0.03860433
INFO:root:[37,   300] training loss: 0.04451442
INFO:root:[37,   350] training loss: 0.04621270
INFO:root:[37,   400] training loss: 0.03782257
INFO:root:epoch37
INFO:root:[38,    50] training loss: 0.01791924
INFO:root:[38,   100] training loss: 0.02869800
INFO:root:[38,   150] training loss: 0.05444411
INFO:root:[38,   200] training loss: 0.05098526
INFO:root:[38,   250] training loss: 0.03882768
INFO:root:[38,   300] training loss: 0.04469095
INFO:root:[38,   350] training loss: 0.04606027
INFO:root:[38,   400] training loss: 0.03785782
INFO:root:epoch38
INFO:root:[39,    50] training loss: 0.01787680
INFO:root:[39,   100] training loss: 0.02878735
INFO:root:[39,   150] training loss: 0.05437082
INFO:root:[39,   200] training loss: 0.05118636
INFO:root:[39,   250] training loss: 0.03878473
INFO:root:[39,   300] training loss: 0.04456566
INFO:root:[39,   350] training loss: 0.04625848
INFO:root:[39,   400] training loss: 0.03795654
INFO:root:epoch39
INFO:root:[40,    50] training loss: 0.01790160
INFO:root:[40,   100] training loss: 0.02882161
INFO:root:[40,   150] training loss: 0.05451966
INFO:root:[40,   200] training loss: 0.05123686
INFO:root:[40,   250] training loss: 0.03920032
INFO:root:[40,   300] training loss: 0.04454816
INFO:root:[40,   350] training loss: 0.04613283
INFO:root:[40,   400] training loss: 0.03788095
INFO:root:epoch40
INFO:root:[41,    50] training loss: 0.01792670
INFO:root:[41,   100] training loss: 0.02887418
INFO:root:[41,   150] training loss: 0.05442608
INFO:root:[41,   200] training loss: 0.05106569
INFO:root:[41,   250] training loss: 0.03885117
INFO:root:[41,   300] training loss: 0.04461385
INFO:root:[41,   350] training loss: 0.04621346
INFO:root:[41,   400] training loss: 0.03776726
INFO:root:epoch41
INFO:root:[42,    50] training loss: 0.01788316
INFO:root:[42,   100] training loss: 0.02883950
INFO:root:[42,   150] training loss: 0.05446646
INFO:root:[42,   200] training loss: 0.05107360
INFO:root:[42,   250] training loss: 0.03888314
INFO:root:[42,   300] training loss: 0.04450547
INFO:root:[42,   350] training loss: 0.04610523
INFO:root:[42,   400] training loss: 0.03807256
INFO:root:epoch42
INFO:root:[43,    50] training loss: 0.01795145
INFO:root:[43,   100] training loss: 0.02876538
INFO:root:[43,   150] training loss: 0.05450862
INFO:root:[43,   200] training loss: 0.05113655
INFO:root:[43,   250] training loss: 0.03901806
INFO:root:[43,   300] training loss: 0.04458092
INFO:root:[43,   350] training loss: 0.04615953
INFO:root:[43,   400] training loss: 0.03795822
INFO:root:epoch43
INFO:root:[44,    50] training loss: 0.01780652
INFO:root:[44,   100] training loss: 0.02870472
INFO:root:[44,   150] training loss: 0.05451885
INFO:root:[44,   200] training loss: 0.05102354
INFO:root:[44,   250] training loss: 0.03890315
INFO:root:[44,   300] training loss: 0.04460259
INFO:root:[44,   350] training loss: 0.04628607
INFO:root:[44,   400] training loss: 0.03801358
INFO:root:epoch44
INFO:root:[45,    50] training loss: 0.01786519
INFO:root:[45,   100] training loss: 0.02885000
INFO:root:[45,   150] training loss: 0.05449260
INFO:root:[45,   200] training loss: 0.05103271
INFO:root:[45,   250] training loss: 0.03890410
INFO:root:[45,   300] training loss: 0.04456239
INFO:root:[45,   350] training loss: 0.04624699
INFO:root:[45,   400] training loss: 0.03797491
INFO:root:epoch45
INFO:root:[46,    50] training loss: 0.01787578
INFO:root:[46,   100] training loss: 0.02878385
INFO:root:[46,   150] training loss: 0.05449991
INFO:root:[46,   200] training loss: 0.05116305
INFO:root:[46,   250] training loss: 0.03925212
INFO:root:[46,   300] training loss: 0.04442465
INFO:root:[46,   350] training loss: 0.04615913
INFO:root:[46,   400] training loss: 0.03786509
INFO:root:epoch46
INFO:root:[47,    50] training loss: 0.01787620
INFO:root:[47,   100] training loss: 0.02877666
INFO:root:[47,   150] training loss: 0.05447686
INFO:root:[47,   200] training loss: 0.05099359
INFO:root:[47,   250] training loss: 0.03889188
INFO:root:[47,   300] training loss: 0.04454461
INFO:root:[47,   350] training loss: 0.04604973
INFO:root:[47,   400] training loss: 0.03779108
INFO:root:epoch47
INFO:root:[48,    50] training loss: 0.01800201
INFO:root:[48,   100] training loss: 0.02887963
INFO:root:[48,   150] training loss: 0.05445342
INFO:root:[48,   200] training loss: 0.05134937
INFO:root:[48,   250] training loss: 0.03904346
INFO:root:[48,   300] training loss: 0.04453926
INFO:root:[48,   350] training loss: 0.04628502
INFO:root:[48,   400] training loss: 0.03781042
INFO:root:epoch48
INFO:root:[49,    50] training loss: 0.01787518
INFO:root:[49,   100] training loss: 0.02876605
INFO:root:[49,   150] training loss: 0.05451600
INFO:root:[49,   200] training loss: 0.05116022
INFO:root:[49,   250] training loss: 0.03885673
INFO:root:[49,   300] training loss: 0.04459547
INFO:root:[49,   350] training loss: 0.04616175
INFO:root:[49,   400] training loss: 0.03783956
INFO:root:epoch49
INFO:root:[50,    50] training loss: 0.01785320
INFO:root:[50,   100] training loss: 0.02885239
INFO:root:[50,   150] training loss: 0.05460612
INFO:root:[50,   200] training loss: 0.05097517
INFO:root:[50,   250] training loss: 0.03898929
INFO:root:[50,   300] training loss: 0.04472389
INFO:root:[50,   350] training loss: 0.04618687
INFO:root:[50,   400] training loss: 0.03800529
INFO:root:Finished Training
INFO:root:Accuracy of the network on the 6256 test images: 75 %
INFO:root:                   precision    recall  f1-score   support

          unknown     0.1203    0.0602    0.0802       266
           CD4+ T     0.5115    0.8151    0.6285       876
           CD8+ T     0.2055    0.0426    0.0706       352
 CD15+ neutrophil     0.9406    0.9828    0.9612      3671
   CD14+ monocyte     0.3416    0.6587    0.4499       252
          CD19+ B     0.0645    0.0111    0.0190       180
         CD56+ NK     1.0000    0.0076    0.0150       132
              NKT     0.1538    0.0091    0.0172       220
       eosinophil     0.7840    0.7329    0.7576       307

         accuracy                         0.7591      6256
        macro avg     0.4580    0.3689    0.3332      6256
     weighted avg     0.7208    0.7591    0.7162      6256

INFO:root:    unknown    CD4+ T    CD8+ T   CD15+ neutrophil   CD14+ monocyte   CD19+ B   CD56+ NK       NKT   eosinophil
0  0.080201  0.628521  0.070588           0.961236         0.449864  0.018957   0.015038  0.017167     0.757576
INFO:root:statistics used: {'mean': tensor([0.1728, 0.1691]), 'std': tensor([0.0640, 0.0627])}
INFO:root:train dataset: 131886, test dataset: 6256
INFO:root:used only channels: [0, 8]; only classes: None
INFO:root:epoch0
INFO:root:[1,    50] training loss: 0.04015625
INFO:root:[1,   100] training loss: 0.03836205
INFO:root:[1,   150] training loss: 0.05514223
INFO:root:[1,   200] training loss: 0.05680258
INFO:root:[1,   250] training loss: 0.07615625
INFO:root:[1,   300] training loss: 0.06421023
INFO:root:[1,   350] training loss: 0.05671992
INFO:root:[1,   400] training loss: 0.06699740
INFO:root:epoch1
INFO:root:[2,    50] training loss: 0.03166112
INFO:root:[2,   100] training loss: 0.03225333
INFO:root:[2,   150] training loss: 0.04402169
INFO:root:[2,   200] training loss: 0.04690772
INFO:root:[2,   250] training loss: 0.05433758
INFO:root:[2,   300] training loss: 0.05090962
INFO:root:[2,   350] training loss: 0.05384902
INFO:root:[2,   400] training loss: 0.06142610
INFO:root:epoch2
INFO:root:[3,    50] training loss: 0.03811064
INFO:root:[3,   100] training loss: 0.03262007
INFO:root:[3,   150] training loss: 0.04608945
INFO:root:[3,   200] training loss: 0.05011280
INFO:root:[3,   250] training loss: 0.05228008
INFO:root:[3,   300] training loss: 0.04967959
INFO:root:[3,   350] training loss: 0.05027735
INFO:root:[3,   400] training loss: 0.05744916
INFO:root:epoch3
INFO:root:[4,    50] training loss: 0.03352486
INFO:root:[4,   100] training loss: 0.03037289
INFO:root:[4,   150] training loss: 0.04620835
INFO:root:[4,   200] training loss: 0.04993933
INFO:root:[4,   250] training loss: 0.05334789
INFO:root:[4,   300] training loss: 0.05150052
INFO:root:[4,   350] training loss: 0.05126996
INFO:root:[4,   400] training loss: 0.05723249
INFO:root:epoch4
INFO:root:[5,    50] training loss: 0.03144068
INFO:root:[5,   100] training loss: 0.03038213
INFO:root:[5,   150] training loss: 0.04974899
INFO:root:[5,   200] training loss: 0.05275569
INFO:root:[5,   250] training loss: 0.05174541
INFO:root:[5,   300] training loss: 0.04950125
INFO:root:[5,   350] training loss: 0.05287829
INFO:root:[5,   400] training loss: 0.05388401
INFO:root:epoch5
INFO:root:[6,    50] training loss: 0.02691611
INFO:root:[6,   100] training loss: 0.02886034
INFO:root:[6,   150] training loss: 0.04803624
INFO:root:[6,   200] training loss: 0.05178097
INFO:root:[6,   250] training loss: 0.05385753
INFO:root:[6,   300] training loss: 0.05037127
INFO:root:[6,   350] training loss: 0.05018914
INFO:root:[6,   400] training loss: 0.04888865
INFO:root:epoch6
INFO:root:[7,    50] training loss: 0.02521037
INFO:root:[7,   100] training loss: 0.02794653
INFO:root:[7,   150] training loss: 0.04562673
INFO:root:[7,   200] training loss: 0.05168815
INFO:root:[7,   250] training loss: 0.05167731
INFO:root:[7,   300] training loss: 0.05079991
INFO:root:[7,   350] training loss: 0.05009989
INFO:root:[7,   400] training loss: 0.04683659
INFO:root:epoch7
INFO:root:[8,    50] training loss: 0.03851720
INFO:root:[8,   100] training loss: 0.03799291
INFO:root:[8,   150] training loss: 0.06219076
INFO:root:[8,   200] training loss: 0.05835249
INFO:root:[8,   250] training loss: 0.05486961
INFO:root:[8,   300] training loss: 0.05112954
INFO:root:[8,   350] training loss: 0.04916418
INFO:root:[8,   400] training loss: 0.03850920
INFO:root:epoch8
INFO:root:[9,    50] training loss: 0.02168437
INFO:root:[9,   100] training loss: 0.03175673
INFO:root:[9,   150] training loss: 0.05811958
INFO:root:[9,   200] training loss: 0.05615249
INFO:root:[9,   250] training loss: 0.05156308
INFO:root:[9,   300] training loss: 0.04993490
INFO:root:[9,   350] training loss: 0.04938417
INFO:root:[9,   400] training loss: 0.03977781
INFO:root:epoch9
INFO:root:[10,    50] training loss: 0.01877119
INFO:root:[10,   100] training loss: 0.02980667
INFO:root:[10,   150] training loss: 0.05621633
INFO:root:[10,   200] training loss: 0.05532643
INFO:root:[10,   250] training loss: 0.04945923
INFO:root:[10,   300] training loss: 0.04898172
INFO:root:[10,   350] training loss: 0.04959867
INFO:root:[10,   400] training loss: 0.03977343
INFO:root:epoch10
INFO:root:[11,    50] training loss: 0.01767625
INFO:root:[11,   100] training loss: 0.02887116
INFO:root:[11,   150] training loss: 0.05493161
INFO:root:[11,   200] training loss: 0.05443454
INFO:root:[11,   250] training loss: 0.04729055
INFO:root:[11,   300] training loss: 0.04819913
INFO:root:[11,   350] training loss: 0.04984651
INFO:root:[11,   400] training loss: 0.03977218
INFO:root:epoch11
INFO:root:[12,    50] training loss: 0.01718077
INFO:root:[12,   100] training loss: 0.02827857
INFO:root:[12,   150] training loss: 0.05385090
INFO:root:[12,   200] training loss: 0.05383742
INFO:root:[12,   250] training loss: 0.04528044
INFO:root:[12,   300] training loss: 0.04745382
INFO:root:[12,   350] training loss: 0.04990490
INFO:root:[12,   400] training loss: 0.03974695
INFO:root:epoch12
INFO:root:[13,    50] training loss: 0.01684588
INFO:root:[13,   100] training loss: 0.02772168
INFO:root:[13,   150] training loss: 0.05267453
INFO:root:[13,   200] training loss: 0.05307155
INFO:root:[13,   250] training loss: 0.04307774
INFO:root:[13,   300] training loss: 0.04672609
INFO:root:[13,   350] training loss: 0.04986338
INFO:root:[13,   400] training loss: 0.03990116
INFO:root:epoch13
INFO:root:[14,    50] training loss: 0.01652991
INFO:root:[14,   100] training loss: 0.02724538
INFO:root:[14,   150] training loss: 0.05173560
INFO:root:[14,   200] training loss: 0.05220681
INFO:root:[14,   250] training loss: 0.04066858
INFO:root:[14,   300] training loss: 0.04591601
INFO:root:[14,   350] training loss: 0.04962827
INFO:root:[14,   400] training loss: 0.04024818
INFO:root:epoch14
INFO:root:[15,    50] training loss: 0.01647624
INFO:root:[15,   100] training loss: 0.02736192
INFO:root:[15,   150] training loss: 0.05370423
INFO:root:[15,   200] training loss: 0.05257022
INFO:root:[15,   250] training loss: 0.04232609
INFO:root:[15,   300] training loss: 0.04619801
INFO:root:[15,   350] training loss: 0.04832658
INFO:root:[15,   400] training loss: 0.03656969
INFO:root:epoch15
INFO:root:[16,    50] training loss: 0.01636730
INFO:root:[16,   100] training loss: 0.02678301
INFO:root:[16,   150] training loss: 0.05296454
INFO:root:[16,   200] training loss: 0.05253112
INFO:root:[16,   250] training loss: 0.04037337
INFO:root:[16,   300] training loss: 0.04551414
INFO:root:[16,   350] training loss: 0.04797988
INFO:root:[16,   400] training loss: 0.03731451
INFO:root:epoch16
INFO:root:[17,    50] training loss: 0.01635296
INFO:root:[17,   100] training loss: 0.02641736
INFO:root:[17,   150] training loss: 0.05231661
INFO:root:[17,   200] training loss: 0.05235523
INFO:root:[17,   250] training loss: 0.03951408
INFO:root:[17,   300] training loss: 0.04499757
INFO:root:[17,   350] training loss: 0.04784231
INFO:root:[17,   400] training loss: 0.03792068
INFO:root:epoch17
INFO:root:[18,    50] training loss: 0.01621944
INFO:root:[18,   100] training loss: 0.02608713
INFO:root:[18,   150] training loss: 0.05201252
INFO:root:[18,   200] training loss: 0.05234339
INFO:root:[18,   250] training loss: 0.03901701
INFO:root:[18,   300] training loss: 0.04462845
INFO:root:[18,   350] training loss: 0.04781929
INFO:root:[18,   400] training loss: 0.03812012
INFO:root:epoch18
INFO:root:[19,    50] training loss: 0.01623235
INFO:root:[19,   100] training loss: 0.02592098
INFO:root:[19,   150] training loss: 0.05152512
INFO:root:[19,   200] training loss: 0.05236191
INFO:root:[19,   250] training loss: 0.03865084
INFO:root:[19,   300] training loss: 0.04443366
INFO:root:[19,   350] training loss: 0.04774317
INFO:root:[19,   400] training loss: 0.03849163
INFO:root:epoch19
INFO:root:[20,    50] training loss: 0.01627677
INFO:root:[20,   100] training loss: 0.02570268
INFO:root:[20,   150] training loss: 0.05128208
INFO:root:[20,   200] training loss: 0.05210817
INFO:root:[20,   250] training loss: 0.03864465
INFO:root:[20,   300] training loss: 0.04439825
INFO:root:[20,   350] training loss: 0.04783637
INFO:root:[20,   400] training loss: 0.03858335
INFO:root:epoch20
INFO:root:[21,    50] training loss: 0.01620911
INFO:root:[21,   100] training loss: 0.02563951
INFO:root:[21,   150] training loss: 0.05091671
INFO:root:[21,   200] training loss: 0.05193425
INFO:root:[21,   250] training loss: 0.03807928
INFO:root:[21,   300] training loss: 0.04425955
INFO:root:[21,   350] training loss: 0.04797222
INFO:root:[21,   400] training loss: 0.03844391
INFO:root:epoch21
INFO:root:[22,    50] training loss: 0.01620260
INFO:root:[22,   100] training loss: 0.02550418
INFO:root:[22,   150] training loss: 0.05090686
INFO:root:[22,   200] training loss: 0.05209453
INFO:root:[22,   250] training loss: 0.03790196
INFO:root:[22,   300] training loss: 0.04419499
INFO:root:[22,   350] training loss: 0.04773365
INFO:root:[22,   400] training loss: 0.03830192
INFO:root:epoch22
INFO:root:[23,    50] training loss: 0.01617428
INFO:root:[23,   100] training loss: 0.02553494
INFO:root:[23,   150] training loss: 0.05098301
INFO:root:[23,   200] training loss: 0.05216111
INFO:root:[23,   250] training loss: 0.03774383
INFO:root:[23,   300] training loss: 0.04405004
INFO:root:[23,   350] training loss: 0.04766524
INFO:root:[23,   400] training loss: 0.03814896
INFO:root:epoch23
INFO:root:[24,    50] training loss: 0.01620057
INFO:root:[24,   100] training loss: 0.02546580
INFO:root:[24,   150] training loss: 0.05098437
INFO:root:[24,   200] training loss: 0.05202988
INFO:root:[24,   250] training loss: 0.03802747
INFO:root:[24,   300] training loss: 0.04414514
INFO:root:[24,   350] training loss: 0.04778222
INFO:root:[24,   400] training loss: 0.03814741
INFO:root:epoch24
INFO:root:[25,    50] training loss: 0.01616018
INFO:root:[25,   100] training loss: 0.02539708
INFO:root:[25,   150] training loss: 0.05084609
INFO:root:[25,   200] training loss: 0.05190962
INFO:root:[25,   250] training loss: 0.03782774
INFO:root:[25,   300] training loss: 0.04432032
INFO:root:[25,   350] training loss: 0.04768814
INFO:root:[25,   400] training loss: 0.03830669
INFO:root:epoch25
INFO:root:[26,    50] training loss: 0.01614697
INFO:root:[26,   100] training loss: 0.02538704
INFO:root:[26,   150] training loss: 0.05083186
INFO:root:[26,   200] training loss: 0.05202848
INFO:root:[26,   250] training loss: 0.03818732
INFO:root:[26,   300] training loss: 0.04435389
INFO:root:[26,   350] training loss: 0.04779612
INFO:root:[26,   400] training loss: 0.03829156
INFO:root:epoch26
INFO:root:[27,    50] training loss: 0.01616662
INFO:root:[27,   100] training loss: 0.02541693
INFO:root:[27,   150] training loss: 0.05082205
INFO:root:[27,   200] training loss: 0.05189954
INFO:root:[27,   250] training loss: 0.03770146
INFO:root:[27,   300] training loss: 0.04414559
INFO:root:[27,   350] training loss: 0.04772917
INFO:root:[27,   400] training loss: 0.03809120
INFO:root:epoch27
INFO:root:[28,    50] training loss: 0.01623475
INFO:root:[28,   100] training loss: 0.02545588
INFO:root:[28,   150] training loss: 0.05093221
INFO:root:[28,   200] training loss: 0.05204399
INFO:root:[28,   250] training loss: 0.03770260
INFO:root:[28,   300] training loss: 0.04411836
INFO:root:[28,   350] training loss: 0.04766656
INFO:root:[28,   400] training loss: 0.03835164
INFO:root:epoch28
INFO:root:[29,    50] training loss: 0.01613884
INFO:root:[29,   100] training loss: 0.02540843
INFO:root:[29,   150] training loss: 0.05079396
INFO:root:[29,   200] training loss: 0.05189258
INFO:root:[29,   250] training loss: 0.03796577
INFO:root:[29,   300] training loss: 0.04395910
INFO:root:[29,   350] training loss: 0.04770937
INFO:root:[29,   400] training loss: 0.03823949
INFO:root:epoch29
INFO:root:[30,    50] training loss: 0.01611868
INFO:root:[30,   100] training loss: 0.02535255
INFO:root:[30,   150] training loss: 0.05077775
INFO:root:[30,   200] training loss: 0.05203001
INFO:root:[30,   250] training loss: 0.03773060
INFO:root:[30,   300] training loss: 0.04419813
INFO:root:[30,   350] training loss: 0.04779505
INFO:root:[30,   400] training loss: 0.03813183
INFO:root:epoch30
INFO:root:[31,    50] training loss: 0.01612539
INFO:root:[31,   100] training loss: 0.02536468
INFO:root:[31,   150] training loss: 0.05072642
INFO:root:[31,   200] training loss: 0.05201545
INFO:root:[31,   250] training loss: 0.03784236
INFO:root:[31,   300] training loss: 0.04416592
INFO:root:[31,   350] training loss: 0.04762515
INFO:root:[31,   400] training loss: 0.03809908
INFO:root:epoch31
INFO:root:[32,    50] training loss: 0.01620494
INFO:root:[32,   100] training loss: 0.02544727
INFO:root:[32,   150] training loss: 0.05077271
INFO:root:[32,   200] training loss: 0.05191415
INFO:root:[32,   250] training loss: 0.03782665
INFO:root:[32,   300] training loss: 0.04387856
INFO:root:[32,   350] training loss: 0.04761089
INFO:root:[32,   400] training loss: 0.03819782
INFO:root:epoch32
INFO:root:[33,    50] training loss: 0.01620436
INFO:root:[33,   100] training loss: 0.02538816
INFO:root:[33,   150] training loss: 0.05078270
INFO:root:[33,   200] training loss: 0.05202286
INFO:root:[33,   250] training loss: 0.03787339
INFO:root:[33,   300] training loss: 0.04407046
INFO:root:[33,   350] training loss: 0.04763379
INFO:root:[33,   400] training loss: 0.03811600
INFO:root:epoch33
INFO:root:[34,    50] training loss: 0.01614834
INFO:root:[34,   100] training loss: 0.02540103
INFO:root:[34,   150] training loss: 0.05079818
INFO:root:[34,   200] training loss: 0.05190227
INFO:root:[34,   250] training loss: 0.03768432
INFO:root:[34,   300] training loss: 0.04415359
INFO:root:[34,   350] training loss: 0.04774681
INFO:root:[34,   400] training loss: 0.03836251
INFO:root:epoch34
INFO:root:[35,    50] training loss: 0.01608875
INFO:root:[35,   100] training loss: 0.02538026
INFO:root:[35,   150] training loss: 0.05072306
INFO:root:[35,   200] training loss: 0.05197798
INFO:root:[35,   250] training loss: 0.03781606
INFO:root:[35,   300] training loss: 0.04417364
INFO:root:[35,   350] training loss: 0.04777959
INFO:root:[35,   400] training loss: 0.03849672
INFO:root:epoch35
INFO:root:[36,    50] training loss: 0.01618390
INFO:root:[36,   100] training loss: 0.02537611
INFO:root:[36,   150] training loss: 0.05074292
INFO:root:[36,   200] training loss: 0.05205169
INFO:root:[36,   250] training loss: 0.03769144
INFO:root:[36,   300] training loss: 0.04409030
INFO:root:[36,   350] training loss: 0.04779701
INFO:root:[36,   400] training loss: 0.03818937
INFO:root:epoch36
INFO:root:[37,    50] training loss: 0.01619835
INFO:root:[37,   100] training loss: 0.02537178
INFO:root:[37,   150] training loss: 0.05069661
INFO:root:[37,   200] training loss: 0.05192321
INFO:root:[37,   250] training loss: 0.03778597
INFO:root:[37,   300] training loss: 0.04392452
INFO:root:[37,   350] training loss: 0.04771125
INFO:root:[37,   400] training loss: 0.03820343
INFO:root:epoch37
INFO:root:[38,    50] training loss: 0.01607927
INFO:root:[38,   100] training loss: 0.02539839
INFO:root:[38,   150] training loss: 0.05067366
INFO:root:[38,   200] training loss: 0.05193271
INFO:root:[38,   250] training loss: 0.03779412
INFO:root:[38,   300] training loss: 0.04412123
INFO:root:[38,   350] training loss: 0.04784504
INFO:root:[38,   400] training loss: 0.03815043
INFO:root:epoch38
INFO:root:[39,    50] training loss: 0.01614688
INFO:root:[39,   100] training loss: 0.02534226
INFO:root:[39,   150] training loss: 0.05080535
INFO:root:[39,   200] training loss: 0.05192476
INFO:root:[39,   250] training loss: 0.03767691
INFO:root:[39,   300] training loss: 0.04399352
INFO:root:[39,   350] training loss: 0.04763521
INFO:root:[39,   400] training loss: 0.03831176
INFO:root:epoch39
INFO:root:[40,    50] training loss: 0.01614726
INFO:root:[40,   100] training loss: 0.02540900
INFO:root:[40,   150] training loss: 0.05080458
INFO:root:[40,   200] training loss: 0.05206680
INFO:root:[40,   250] training loss: 0.03791243
INFO:root:[40,   300] training loss: 0.04409073
INFO:root:[40,   350] training loss: 0.04769414
INFO:root:[40,   400] training loss: 0.03837215
INFO:root:epoch40
INFO:root:[41,    50] training loss: 0.01613116
INFO:root:[41,   100] training loss: 0.02538232
INFO:root:[41,   150] training loss: 0.05070751
INFO:root:[41,   200] training loss: 0.05201640
INFO:root:[41,   250] training loss: 0.03813138
INFO:root:[41,   300] training loss: 0.04425222
INFO:root:[41,   350] training loss: 0.04774270
INFO:root:[41,   400] training loss: 0.03827362
INFO:root:epoch41
INFO:root:[42,    50] training loss: 0.01620385
INFO:root:[42,   100] training loss: 0.02543479
INFO:root:[42,   150] training loss: 0.05071865
INFO:root:[42,   200] training loss: 0.05204720
INFO:root:[42,   250] training loss: 0.03771048
INFO:root:[42,   300] training loss: 0.04418915
INFO:root:[42,   350] training loss: 0.04765696
INFO:root:[42,   400] training loss: 0.03845670
INFO:root:epoch42
INFO:root:[43,    50] training loss: 0.01620989
INFO:root:[43,   100] training loss: 0.02540992
INFO:root:[43,   150] training loss: 0.05076635
INFO:root:[43,   200] training loss: 0.05213841
INFO:root:[43,   250] training loss: 0.03787547
INFO:root:[43,   300] training loss: 0.04416769
INFO:root:[43,   350] training loss: 0.04770008
INFO:root:[43,   400] training loss: 0.03811688
INFO:root:epoch43
INFO:root:[44,    50] training loss: 0.01619870
INFO:root:[44,   100] training loss: 0.02540889
INFO:root:[44,   150] training loss: 0.05077970
INFO:root:[44,   200] training loss: 0.05205874
INFO:root:[44,   250] training loss: 0.03813374
INFO:root:[44,   300] training loss: 0.04402894
INFO:root:[44,   350] training loss: 0.04763864
INFO:root:[44,   400] training loss: 0.03811010
INFO:root:epoch44
INFO:root:[45,    50] training loss: 0.01627887
INFO:root:[45,   100] training loss: 0.02533205
INFO:root:[45,   150] training loss: 0.05087294
INFO:root:[45,   200] training loss: 0.05201999
INFO:root:[45,   250] training loss: 0.03777784
INFO:root:[45,   300] training loss: 0.04407010
INFO:root:[45,   350] training loss: 0.04777442
INFO:root:[45,   400] training loss: 0.03821526
INFO:root:epoch45
INFO:root:[46,    50] training loss: 0.01616602
INFO:root:[46,   100] training loss: 0.02536768
INFO:root:[46,   150] training loss: 0.05071550
INFO:root:[46,   200] training loss: 0.05195944
INFO:root:[46,   250] training loss: 0.03786034
INFO:root:[46,   300] training loss: 0.04406036
INFO:root:[46,   350] training loss: 0.04765842
INFO:root:[46,   400] training loss: 0.03828380
INFO:root:epoch46
INFO:root:[47,    50] training loss: 0.01610507
INFO:root:[47,   100] training loss: 0.02538754
INFO:root:[47,   150] training loss: 0.05077052
INFO:root:[47,   200] training loss: 0.05189882
INFO:root:[47,   250] training loss: 0.03770723
INFO:root:[47,   300] training loss: 0.04402469
INFO:root:[47,   350] training loss: 0.04767302
INFO:root:[47,   400] training loss: 0.03844296
INFO:root:epoch47
INFO:root:[48,    50] training loss: 0.01610519
INFO:root:[48,   100] training loss: 0.02535704
INFO:root:[48,   150] training loss: 0.05080543
INFO:root:[48,   200] training loss: 0.05196743
INFO:root:[48,   250] training loss: 0.03781671
INFO:root:[48,   300] training loss: 0.04412076
INFO:root:[48,   350] training loss: 0.04777560
INFO:root:[48,   400] training loss: 0.03829602
INFO:root:epoch48
INFO:root:[49,    50] training loss: 0.01618447
INFO:root:[49,   100] training loss: 0.02543129
INFO:root:[49,   150] training loss: 0.05075929
INFO:root:[49,   200] training loss: 0.05198033
INFO:root:[49,   250] training loss: 0.03773113
INFO:root:[49,   300] training loss: 0.04423482
INFO:root:[49,   350] training loss: 0.04774664
INFO:root:[49,   400] training loss: 0.03811979
INFO:root:epoch49
INFO:root:[50,    50] training loss: 0.01615923
INFO:root:[50,   100] training loss: 0.02542854
INFO:root:[50,   150] training loss: 0.05077417
INFO:root:[50,   200] training loss: 0.05192739
INFO:root:[50,   250] training loss: 0.03760774
INFO:root:[50,   300] training loss: 0.04424375
INFO:root:[50,   350] training loss: 0.04780952
INFO:root:[50,   400] training loss: 0.03830054
INFO:root:Finished Training
INFO:root:Accuracy of the network on the 6256 test images: 78 %
INFO:root:                   precision    recall  f1-score   support

          unknown     0.1151    0.0724    0.0889       221
           CD4+ T     0.5207    0.8787    0.6539       874
           CD8+ T     0.2283    0.0545    0.0881       385
 CD15+ neutrophil     0.9560    0.9946    0.9749      3671
   CD14+ monocyte     0.4853    0.7868    0.6003       272
          CD19+ B     0.0000    0.0000    0.0000       172
         CD56+ NK     0.0833    0.0073    0.0134       137
              NKT     0.0000    0.0000    0.0000       198
       eosinophil     0.9317    0.7945    0.8576       326

         accuracy                         0.7880      6256
        macro avg     0.3689    0.3988    0.3641      6256
     weighted avg     0.7233    0.7880    0.7431      6256

INFO:root:    unknown    CD4+ T   CD8+ T   CD15+ neutrophil   CD14+ monocyte   CD19+ B   CD56+ NK   NKT   eosinophil
0  0.088889  0.653895  0.08805             0.9749         0.600281       0.0   0.013423   0.0     0.857616
INFO:root:statistics used: {'mean': tensor([0.1729, 0.1692]), 'std': tensor([0.0639, 0.0625])}
INFO:root:train dataset: 132012, test dataset: 6256
INFO:root:used only channels: [0, 8]; only classes: None
INFO:root:epoch0
INFO:root:[1,    50] training loss: 0.04281476
INFO:root:[1,   100] training loss: 0.03943147
INFO:root:[1,   150] training loss: 0.04413863
INFO:root:[1,   200] training loss: 0.05001357
INFO:root:[1,   250] training loss: 0.06059136
INFO:root:[1,   300] training loss: 0.07979590
INFO:root:[1,   350] training loss: 0.06665129
INFO:root:[1,   400] training loss: 0.06085958
INFO:root:epoch1
INFO:root:[2,    50] training loss: 0.03812147
INFO:root:[2,   100] training loss: 0.03360983
INFO:root:[2,   150] training loss: 0.04095617
INFO:root:[2,   200] training loss: 0.04766494
INFO:root:[2,   250] training loss: 0.05197393
INFO:root:[2,   300] training loss: 0.06412583
INFO:root:[2,   350] training loss: 0.05756359
INFO:root:[2,   400] training loss: 0.05355594
INFO:root:epoch2
INFO:root:[3,    50] training loss: 0.04246639
INFO:root:[3,   100] training loss: 0.03742884
INFO:root:[3,   150] training loss: 0.04066996
INFO:root:[3,   200] training loss: 0.04687163
INFO:root:[3,   250] training loss: 0.04883435
INFO:root:[3,   300] training loss: 0.05524960
INFO:root:[3,   350] training loss: 0.05652660
INFO:root:[3,   400] training loss: 0.05630793
INFO:root:epoch3
INFO:root:[4,    50] training loss: 0.03998062
INFO:root:[4,   100] training loss: 0.03708448
INFO:root:[4,   150] training loss: 0.04795935
INFO:root:[4,   200] training loss: 0.04887946
INFO:root:[4,   250] training loss: 0.04973894
INFO:root:[4,   300] training loss: 0.05495940
INFO:root:[4,   350] training loss: 0.05372442
INFO:root:[4,   400] training loss: 0.05508537
INFO:root:epoch4
INFO:root:[5,    50] training loss: 0.03965570
INFO:root:[5,   100] training loss: 0.03505444
INFO:root:[5,   150] training loss: 0.04685323
INFO:root:[5,   200] training loss: 0.04754026
INFO:root:[5,   250] training loss: 0.04603256
INFO:root:[5,   300] training loss: 0.04610080
INFO:root:[5,   350] training loss: 0.04977040
INFO:root:[5,   400] training loss: 0.05097794
INFO:root:epoch5
INFO:root:[6,    50] training loss: 0.03736097
INFO:root:[6,   100] training loss: 0.03402438
INFO:root:[6,   150] training loss: 0.04718837
INFO:root:[6,   200] training loss: 0.04952417
INFO:root:[6,   250] training loss: 0.05115872
INFO:root:[6,   300] training loss: 0.05396027
INFO:root:[6,   350] training loss: 0.05509146
INFO:root:[6,   400] training loss: 0.04397192
INFO:root:epoch6
INFO:root:[7,    50] training loss: 0.03591732
INFO:root:[7,   100] training loss: 0.03292218
INFO:root:[7,   150] training loss: 0.04708264
INFO:root:[7,   200] training loss: 0.04959099
INFO:root:[7,   250] training loss: 0.05043548
INFO:root:[7,   300] training loss: 0.05083721
INFO:root:[7,   350] training loss: 0.05343806
INFO:root:[7,   400] training loss: 0.04792067
INFO:root:epoch7
INFO:root:[8,    50] training loss: 0.05238168
INFO:root:[8,   100] training loss: 0.04514728
INFO:root:[8,   150] training loss: 0.05835423
INFO:root:[8,   200] training loss: 0.05604475
INFO:root:[8,   250] training loss: 0.05762463
INFO:root:[8,   300] training loss: 0.05415522
INFO:root:[8,   350] training loss: 0.05264658
INFO:root:[8,   400] training loss: 0.04239467
INFO:root:epoch8
INFO:root:[9,    50] training loss: 0.03291551
INFO:root:[9,   100] training loss: 0.03596972
INFO:root:[9,   150] training loss: 0.05432303
INFO:root:[9,   200] training loss: 0.05364719
INFO:root:[9,   250] training loss: 0.05442249
INFO:root:[9,   300] training loss: 0.05305340
INFO:root:[9,   350] training loss: 0.05167521
INFO:root:[9,   400] training loss: 0.04223286
INFO:root:epoch9
INFO:root:[10,    50] training loss: 0.02781066
INFO:root:[10,   100] training loss: 0.03340956
INFO:root:[10,   150] training loss: 0.05343065
INFO:root:[10,   200] training loss: 0.05248024
INFO:root:[10,   250] training loss: 0.05225558
INFO:root:[10,   300] training loss: 0.05263000
INFO:root:[10,   350] training loss: 0.05137233
INFO:root:[10,   400] training loss: 0.04216783
INFO:root:epoch10
INFO:root:[11,    50] training loss: 0.02505432
INFO:root:[11,   100] training loss: 0.03211265
INFO:root:[11,   150] training loss: 0.05249669
INFO:root:[11,   200] training loss: 0.05189057
INFO:root:[11,   250] training loss: 0.05020628
INFO:root:[11,   300] training loss: 0.05165349
INFO:root:[11,   350] training loss: 0.05123015
INFO:root:[11,   400] training loss: 0.04182437
INFO:root:epoch11
INFO:root:[12,    50] training loss: 0.02362359
INFO:root:[12,   100] training loss: 0.03143421
INFO:root:[12,   150] training loss: 0.05184379
INFO:root:[12,   200] training loss: 0.05144330
INFO:root:[12,   250] training loss: 0.04835454
INFO:root:[12,   300] training loss: 0.05046671
INFO:root:[12,   350] training loss: 0.05097956
INFO:root:[12,   400] training loss: 0.04146845
INFO:root:epoch12
INFO:root:[13,    50] training loss: 0.02265563
INFO:root:[13,   100] training loss: 0.03075657
INFO:root:[13,   150] training loss: 0.05095867
INFO:root:[13,   200] training loss: 0.05091092
INFO:root:[13,   250] training loss: 0.04644551
INFO:root:[13,   300] training loss: 0.04942047
INFO:root:[13,   350] training loss: 0.05113966
INFO:root:[13,   400] training loss: 0.04145850
INFO:root:epoch13
INFO:root:[14,    50] training loss: 0.02180181
INFO:root:[14,   100] training loss: 0.03022867
INFO:root:[14,   150] training loss: 0.05041988
INFO:root:[14,   200] training loss: 0.05033771
INFO:root:[14,   250] training loss: 0.04464732
INFO:root:[14,   300] training loss: 0.04846088
INFO:root:[14,   350] training loss: 0.05085530
INFO:root:[14,   400] training loss: 0.04169366
INFO:root:epoch14
INFO:root:[15,    50] training loss: 0.02191352
INFO:root:[15,   100] training loss: 0.03128646
INFO:root:[15,   150] training loss: 0.05271748
INFO:root:[15,   200] training loss: 0.05181165
INFO:root:[15,   250] training loss: 0.04596833
INFO:root:[15,   300] training loss: 0.05021807
INFO:root:[15,   350] training loss: 0.04939493
INFO:root:[15,   400] training loss: 0.03676026
INFO:root:epoch15
INFO:root:[16,    50] training loss: 0.02151398
INFO:root:[16,   100] training loss: 0.03078658
INFO:root:[16,   150] training loss: 0.05227487
INFO:root:[16,   200] training loss: 0.05127049
INFO:root:[16,   250] training loss: 0.04446712
INFO:root:[16,   300] training loss: 0.04956877
INFO:root:[16,   350] training loss: 0.04926372
INFO:root:[16,   400] training loss: 0.03776106
INFO:root:epoch16
INFO:root:[17,    50] training loss: 0.02132496
INFO:root:[17,   100] training loss: 0.03059407
INFO:root:[17,   150] training loss: 0.05175297
INFO:root:[17,   200] training loss: 0.05086696
INFO:root:[17,   250] training loss: 0.04379381
INFO:root:[17,   300] training loss: 0.04836046
INFO:root:[17,   350] training loss: 0.04921099
INFO:root:[17,   400] training loss: 0.03775339
INFO:root:epoch17
INFO:root:[18,    50] training loss: 0.02107617
INFO:root:[18,   100] training loss: 0.03040317
INFO:root:[18,   150] training loss: 0.05151501
INFO:root:[18,   200] training loss: 0.05072969
INFO:root:[18,   250] training loss: 0.04322767
INFO:root:[18,   300] training loss: 0.04784956
INFO:root:[18,   350] training loss: 0.04925936
INFO:root:[18,   400] training loss: 0.03829700
INFO:root:epoch18
INFO:root:[19,    50] training loss: 0.02092895
INFO:root:[19,   100] training loss: 0.03015073
INFO:root:[19,   150] training loss: 0.05133039
INFO:root:[19,   200] training loss: 0.05057410
INFO:root:[19,   250] training loss: 0.04324744
INFO:root:[19,   300] training loss: 0.04794213
INFO:root:[19,   350] training loss: 0.04945726
INFO:root:[19,   400] training loss: 0.03886846
INFO:root:epoch19
INFO:root:[20,    50] training loss: 0.02094848
INFO:root:[20,   100] training loss: 0.02999065
INFO:root:[20,   150] training loss: 0.05115978
INFO:root:[20,   200] training loss: 0.05041059
INFO:root:[20,   250] training loss: 0.04263147
INFO:root:[20,   300] training loss: 0.04730909
INFO:root:[20,   350] training loss: 0.04916862
INFO:root:[20,   400] training loss: 0.03852251
INFO:root:epoch20
INFO:root:[21,    50] training loss: 0.02065888
INFO:root:[21,   100] training loss: 0.02978290
INFO:root:[21,   150] training loss: 0.05088265
INFO:root:[21,   200] training loss: 0.05040577
INFO:root:[21,   250] training loss: 0.04248658
INFO:root:[21,   300] training loss: 0.04752905
INFO:root:[21,   350] training loss: 0.04921716
INFO:root:[21,   400] training loss: 0.03913085
INFO:root:epoch21
INFO:root:[22,    50] training loss: 0.02063727
INFO:root:[22,   100] training loss: 0.02982168
INFO:root:[22,   150] training loss: 0.05098759
INFO:root:[22,   200] training loss: 0.05035562
INFO:root:[22,   250] training loss: 0.04225721
INFO:root:[22,   300] training loss: 0.04711132
INFO:root:[22,   350] training loss: 0.04905363
INFO:root:[22,   400] training loss: 0.03818984
INFO:root:epoch22
INFO:root:[23,    50] training loss: 0.02060230
INFO:root:[23,   100] training loss: 0.02970507
INFO:root:[23,   150] training loss: 0.05101555
INFO:root:[23,   200] training loss: 0.05035248
INFO:root:[23,   250] training loss: 0.04222767
INFO:root:[23,   300] training loss: 0.04739162
INFO:root:[23,   350] training loss: 0.04918635
INFO:root:[23,   400] training loss: 0.03797178
INFO:root:epoch23
INFO:root:[24,    50] training loss: 0.02058906
INFO:root:[24,   100] training loss: 0.02976441
INFO:root:[24,   150] training loss: 0.05093582
INFO:root:[24,   200] training loss: 0.05036938
INFO:root:[24,   250] training loss: 0.04227258
INFO:root:[24,   300] training loss: 0.04741056
INFO:root:[24,   350] training loss: 0.04901109
INFO:root:[24,   400] training loss: 0.03820522
INFO:root:epoch24
INFO:root:[25,    50] training loss: 0.02062503
INFO:root:[25,   100] training loss: 0.02977757
INFO:root:[25,   150] training loss: 0.05099506
INFO:root:[25,   200] training loss: 0.05026078
INFO:root:[25,   250] training loss: 0.04220664
INFO:root:[25,   300] training loss: 0.04695197
INFO:root:[25,   350] training loss: 0.04909735
INFO:root:[25,   400] training loss: 0.03791986
INFO:root:epoch25
INFO:root:[26,    50] training loss: 0.02060508
INFO:root:[26,   100] training loss: 0.02980400
INFO:root:[26,   150] training loss: 0.05098993
INFO:root:[26,   200] training loss: 0.05033336
INFO:root:[26,   250] training loss: 0.04214740
INFO:root:[26,   300] training loss: 0.04753596
INFO:root:[26,   350] training loss: 0.04911742
INFO:root:[26,   400] training loss: 0.03771636
INFO:root:epoch26
INFO:root:[27,    50] training loss: 0.02063377
INFO:root:[27,   100] training loss: 0.02969513
INFO:root:[27,   150] training loss: 0.05096578
INFO:root:[27,   200] training loss: 0.05027192
INFO:root:[27,   250] training loss: 0.04225152
INFO:root:[27,   300] training loss: 0.04736219
INFO:root:[27,   350] training loss: 0.04924799
INFO:root:[27,   400] training loss: 0.03867196
INFO:root:epoch27
INFO:root:[28,    50] training loss: 0.02064437
INFO:root:[28,   100] training loss: 0.02981757
INFO:root:[28,   150] training loss: 0.05076108
INFO:root:[28,   200] training loss: 0.05041490
INFO:root:[28,   250] training loss: 0.04216159
INFO:root:[28,   300] training loss: 0.04686349
INFO:root:[28,   350] training loss: 0.04910133
INFO:root:[28,   400] training loss: 0.03833360
INFO:root:epoch28
INFO:root:[29,    50] training loss: 0.02062748
INFO:root:[29,   100] training loss: 0.02971136
INFO:root:[29,   150] training loss: 0.05093417
INFO:root:[29,   200] training loss: 0.05029919
INFO:root:[29,   250] training loss: 0.04235999
INFO:root:[29,   300] training loss: 0.04726921
INFO:root:[29,   350] training loss: 0.04911736
INFO:root:[29,   400] training loss: 0.03859534
INFO:root:epoch29
INFO:root:[30,    50] training loss: 0.02065750
INFO:root:[30,   100] training loss: 0.02987227
INFO:root:[30,   150] training loss: 0.05098458
INFO:root:[30,   200] training loss: 0.05027506
INFO:root:[30,   250] training loss: 0.04213911
INFO:root:[30,   300] training loss: 0.04665389
INFO:root:[30,   350] training loss: 0.04901002
INFO:root:[30,   400] training loss: 0.03893650
INFO:root:epoch30
INFO:root:[31,    50] training loss: 0.02053860
INFO:root:[31,   100] training loss: 0.02971733
INFO:root:[31,   150] training loss: 0.05087204
INFO:root:[31,   200] training loss: 0.05022988
INFO:root:[31,   250] training loss: 0.04208965
INFO:root:[31,   300] training loss: 0.04727058
INFO:root:[31,   350] training loss: 0.04910477
INFO:root:[31,   400] training loss: 0.03821076
INFO:root:epoch31
INFO:root:[32,    50] training loss: 0.02069150
INFO:root:[32,   100] training loss: 0.02963703
INFO:root:[32,   150] training loss: 0.05077160
INFO:root:[32,   200] training loss: 0.05030668
INFO:root:[32,   250] training loss: 0.04215825
INFO:root:[32,   300] training loss: 0.04706747
INFO:root:[32,   350] training loss: 0.04903130
INFO:root:[32,   400] training loss: 0.03863862
INFO:root:epoch32
INFO:root:[33,    50] training loss: 0.02067764
INFO:root:[33,   100] training loss: 0.02972419
INFO:root:[33,   150] training loss: 0.05090850
INFO:root:[33,   200] training loss: 0.05024608
INFO:root:[33,   250] training loss: 0.04217903
INFO:root:[33,   300] training loss: 0.04711366
INFO:root:[33,   350] training loss: 0.04919049
INFO:root:[33,   400] training loss: 0.03854695
INFO:root:epoch33
INFO:root:[34,    50] training loss: 0.02053542
INFO:root:[34,   100] training loss: 0.02964456
INFO:root:[34,   150] training loss: 0.05089663
INFO:root:[34,   200] training loss: 0.05022163
INFO:root:[34,   250] training loss: 0.04219129
INFO:root:[34,   300] training loss: 0.04747680
INFO:root:[34,   350] training loss: 0.04905000
INFO:root:[34,   400] training loss: 0.03869780
INFO:root:epoch34
INFO:root:[35,    50] training loss: 0.02064984
INFO:root:[35,   100] training loss: 0.02964961
INFO:root:[35,   150] training loss: 0.05098799
INFO:root:[35,   200] training loss: 0.05032273
INFO:root:[35,   250] training loss: 0.04232102
INFO:root:[35,   300] training loss: 0.04735292
INFO:root:[35,   350] training loss: 0.04912545
INFO:root:[35,   400] training loss: 0.03896668
INFO:root:epoch35
INFO:root:[36,    50] training loss: 0.02063911
INFO:root:[36,   100] training loss: 0.02974059
INFO:root:[36,   150] training loss: 0.05091086
INFO:root:[36,   200] training loss: 0.05032392
INFO:root:[36,   250] training loss: 0.04204842
INFO:root:[36,   300] training loss: 0.04709579
INFO:root:[36,   350] training loss: 0.04907523
INFO:root:[36,   400] training loss: 0.03835347
INFO:root:epoch36
INFO:root:[37,    50] training loss: 0.02055010
INFO:root:[37,   100] training loss: 0.02970692
INFO:root:[37,   150] training loss: 0.05089368
INFO:root:[37,   200] training loss: 0.05042587
INFO:root:[37,   250] training loss: 0.04207264
INFO:root:[37,   300] training loss: 0.04718617
INFO:root:[37,   350] training loss: 0.04904145
INFO:root:[37,   400] training loss: 0.03840199
INFO:root:epoch37
INFO:root:[38,    50] training loss: 0.02065975
INFO:root:[38,   100] training loss: 0.02971479
INFO:root:[38,   150] training loss: 0.05085042
INFO:root:[38,   200] training loss: 0.05034217
INFO:root:[38,   250] training loss: 0.04238651
INFO:root:[38,   300] training loss: 0.04737061
INFO:root:[38,   350] training loss: 0.04913830
INFO:root:[38,   400] training loss: 0.03854862
INFO:root:epoch38
INFO:root:[39,    50] training loss: 0.02051879
INFO:root:[39,   100] training loss: 0.02974021
INFO:root:[39,   150] training loss: 0.05088923
INFO:root:[39,   200] training loss: 0.05032168
INFO:root:[39,   250] training loss: 0.04206252
INFO:root:[39,   300] training loss: 0.04719701
INFO:root:[39,   350] training loss: 0.04909329
INFO:root:[39,   400] training loss: 0.03846345
INFO:root:epoch39
INFO:root:[40,    50] training loss: 0.02059228
INFO:root:[40,   100] training loss: 0.02964164
INFO:root:[40,   150] training loss: 0.05087732
INFO:root:[40,   200] training loss: 0.05024047
INFO:root:[40,   250] training loss: 0.04215764
INFO:root:[40,   300] training loss: 0.04748786
INFO:root:[40,   350] training loss: 0.04895369
INFO:root:[40,   400] training loss: 0.03805407
INFO:root:epoch40
INFO:root:[41,    50] training loss: 0.02060895
INFO:root:[41,   100] training loss: 0.02965171
INFO:root:[41,   150] training loss: 0.05088672
INFO:root:[41,   200] training loss: 0.05030422
INFO:root:[41,   250] training loss: 0.04234618
INFO:root:[41,   300] training loss: 0.04722894
INFO:root:[41,   350] training loss: 0.04906198
INFO:root:[41,   400] training loss: 0.03826601
INFO:root:epoch41
INFO:root:[42,    50] training loss: 0.02056430
INFO:root:[42,   100] training loss: 0.02975532
INFO:root:[42,   150] training loss: 0.05094949
INFO:root:[42,   200] training loss: 0.05038687
INFO:root:[42,   250] training loss: 0.04209126
INFO:root:[42,   300] training loss: 0.04742654
INFO:root:[42,   350] training loss: 0.04902749
INFO:root:[42,   400] training loss: 0.03787850
INFO:root:epoch42
INFO:root:[43,    50] training loss: 0.02063583
INFO:root:[43,   100] training loss: 0.02968392
INFO:root:[43,   150] training loss: 0.05087157
INFO:root:[43,   200] training loss: 0.05026198
INFO:root:[43,   250] training loss: 0.04200317
INFO:root:[43,   300] training loss: 0.04731619
INFO:root:[43,   350] training loss: 0.04908574
INFO:root:[43,   400] training loss: 0.03811102
INFO:root:epoch43
INFO:root:[44,    50] training loss: 0.02055204
INFO:root:[44,   100] training loss: 0.02962225
INFO:root:[44,   150] training loss: 0.05089826
INFO:root:[44,   200] training loss: 0.05031889
INFO:root:[44,   250] training loss: 0.04207243
INFO:root:[44,   300] training loss: 0.04721006
INFO:root:[44,   350] training loss: 0.04919439
INFO:root:[44,   400] training loss: 0.03829256
INFO:root:epoch44
INFO:root:[45,    50] training loss: 0.02066266
INFO:root:[45,   100] training loss: 0.02980769
INFO:root:[45,   150] training loss: 0.05097401
INFO:root:[45,   200] training loss: 0.05031289
INFO:root:[45,   250] training loss: 0.04203767
INFO:root:[45,   300] training loss: 0.04729143
INFO:root:[45,   350] training loss: 0.04892705
INFO:root:[45,   400] training loss: 0.03873000
INFO:root:epoch45
INFO:root:[46,    50] training loss: 0.02063954
INFO:root:[46,   100] training loss: 0.02966878
INFO:root:[46,   150] training loss: 0.05084458
INFO:root:[46,   200] training loss: 0.05029644
INFO:root:[46,   250] training loss: 0.04214152
INFO:root:[46,   300] training loss: 0.04687741
INFO:root:[46,   350] training loss: 0.04896648
INFO:root:[46,   400] training loss: 0.03833062
INFO:root:epoch46
INFO:root:[47,    50] training loss: 0.02065343
INFO:root:[47,   100] training loss: 0.02961888
INFO:root:[47,   150] training loss: 0.05089897
INFO:root:[47,   200] training loss: 0.05025222
INFO:root:[47,   250] training loss: 0.04216061
INFO:root:[47,   300] training loss: 0.04735467
INFO:root:[47,   350] training loss: 0.04915435
INFO:root:[47,   400] training loss: 0.03862232
INFO:root:epoch47
INFO:root:[48,    50] training loss: 0.02057711
INFO:root:[48,   100] training loss: 0.02962625
INFO:root:[48,   150] training loss: 0.05104256
INFO:root:[48,   200] training loss: 0.05036672
INFO:root:[48,   250] training loss: 0.04221048
INFO:root:[48,   300] training loss: 0.04715896
INFO:root:[48,   350] training loss: 0.04918832
INFO:root:[48,   400] training loss: 0.03857530
INFO:root:epoch48
INFO:root:[49,    50] training loss: 0.02061985
INFO:root:[49,   100] training loss: 0.02976226
INFO:root:[49,   150] training loss: 0.05086523
INFO:root:[49,   200] training loss: 0.05034767
INFO:root:[49,   250] training loss: 0.04236342
INFO:root:[49,   300] training loss: 0.04750429
INFO:root:[49,   350] training loss: 0.04905935
INFO:root:[49,   400] training loss: 0.03872225
INFO:root:epoch49
INFO:root:[50,    50] training loss: 0.02056928
INFO:root:[50,   100] training loss: 0.02967978
INFO:root:[50,   150] training loss: 0.05081040
INFO:root:[50,   200] training loss: 0.05025534
INFO:root:[50,   250] training loss: 0.04234730
INFO:root:[50,   300] training loss: 0.04731772
INFO:root:[50,   350] training loss: 0.04923810
INFO:root:[50,   400] training loss: 0.03842965
INFO:root:Finished Training
INFO:root:Accuracy of the network on the 6256 test images: 66 %
INFO:root:                   precision    recall  f1-score   support

          unknown     0.0833    0.0074    0.0135       272
           CD4+ T     0.5330    0.7731    0.6310       899
           CD8+ T     0.2222    0.0627    0.0978       351
 CD15+ neutrophil     0.9100    0.8378    0.8724      3657
   CD14+ monocyte     0.1875    0.3898    0.2532       254
          CD19+ B     0.0682    0.0186    0.0293       161
         CD56+ NK     0.0000    0.0000    0.0000       140
              NKT     0.1212    0.0195    0.0336       205
       eosinophil     0.3172    0.8454    0.4613       317

         accuracy                         0.6645      6256
        macro avg     0.2714    0.3283    0.2658      6256
     weighted avg     0.6540    0.6645    0.6422      6256

INFO:root:    unknown    CD4+ T    CD8+ T   CD15+ neutrophil   CD14+ monocyte   CD19+ B   CD56+ NK       NKT   eosinophil
0  0.013514  0.630958  0.097778           0.872437         0.253197  0.029268        0.0  0.033613     0.461274
INFO:root:statistics used: {'mean': tensor([0.1729, 0.1692]), 'std': tensor([0.0639, 0.0626])}
INFO:root:train dataset: 132219, test dataset: 6256
INFO:root:used only channels: [0, 8]; only classes: None
INFO:root:epoch0
INFO:root:[1,    50] training loss: 0.05593379
INFO:root:[1,   100] training loss: 0.03819343
INFO:root:[1,   150] training loss: 0.04380356
INFO:root:[1,   200] training loss: 0.06515810
INFO:root:[1,   250] training loss: 0.07895446
INFO:root:[1,   300] training loss: 0.06306226
INFO:root:[1,   350] training loss: 0.05367771
INFO:root:[1,   400] training loss: 0.05766859
INFO:root:epoch1
INFO:root:[2,    50] training loss: 0.03590802
INFO:root:[2,   100] training loss: 0.03258159
INFO:root:[2,   150] training loss: 0.04135783
INFO:root:[2,   200] training loss: 0.05299010
INFO:root:[2,   250] training loss: 0.05390057
INFO:root:[2,   300] training loss: 0.04952768
INFO:root:[2,   350] training loss: 0.04843147
INFO:root:[2,   400] training loss: 0.05204802
INFO:root:epoch2
INFO:root:[3,    50] training loss: 0.04201573
INFO:root:[3,   100] training loss: 0.03415368
INFO:root:[3,   150] training loss: 0.04130264
INFO:root:[3,   200] training loss: 0.05090636
INFO:root:[3,   250] training loss: 0.05340408
INFO:root:[3,   300] training loss: 0.05328634
INFO:root:[3,   350] training loss: 0.05366921
INFO:root:[3,   400] training loss: 0.05423306
INFO:root:epoch3
INFO:root:[4,    50] training loss: 0.04067563
INFO:root:[4,   100] training loss: 0.03326512
INFO:root:[4,   150] training loss: 0.04494769
INFO:root:[4,   200] training loss: 0.05276031
INFO:root:[4,   250] training loss: 0.05553295
INFO:root:[4,   300] training loss: 0.05151941
INFO:root:[4,   350] training loss: 0.05457102
INFO:root:[4,   400] training loss: 0.05385502
INFO:root:epoch4
INFO:root:[5,    50] training loss: 0.03471635
INFO:root:[5,   100] training loss: 0.03145240
INFO:root:[5,   150] training loss: 0.04674015
INFO:root:[5,   200] training loss: 0.05322634
INFO:root:[5,   250] training loss: 0.05445797
INFO:root:[5,   300] training loss: 0.05111046
INFO:root:[5,   350] training loss: 0.05185320
INFO:root:[5,   400] training loss: 0.04947248
INFO:root:epoch5
INFO:root:[6,    50] training loss: 0.03098456
INFO:root:[6,   100] training loss: 0.03063089
INFO:root:[6,   150] training loss: 0.04640328
INFO:root:[6,   200] training loss: 0.05266782
INFO:root:[6,   250] training loss: 0.05105345
INFO:root:[6,   300] training loss: 0.05003566
INFO:root:[6,   350] training loss: 0.05099153
INFO:root:[6,   400] training loss: 0.04516043
INFO:root:epoch6
INFO:root:[7,    50] training loss: 0.02577207
INFO:root:[7,   100] training loss: 0.02867081
INFO:root:[7,   150] training loss: 0.04103888
INFO:root:[7,   200] training loss: 0.05113538
INFO:root:[7,   250] training loss: 0.05025609
INFO:root:[7,   300] training loss: 0.04677292
INFO:root:[7,   350] training loss: 0.04799960
INFO:root:[7,   400] training loss: 0.04002013
INFO:root:epoch7
INFO:root:[8,    50] training loss: 0.04353784
INFO:root:[8,   100] training loss: 0.04077748
INFO:root:[8,   150] training loss: 0.06126341
INFO:root:[8,   200] training loss: 0.05935733
INFO:root:[8,   250] training loss: 0.05774976
INFO:root:[8,   300] training loss: 0.05315147
INFO:root:[8,   350] training loss: 0.05010872
INFO:root:[8,   400] training loss: 0.03326693
INFO:root:epoch8
INFO:root:[9,    50] training loss: 0.02603940
INFO:root:[9,   100] training loss: 0.03280586
INFO:root:[9,   150] training loss: 0.05607667
INFO:root:[9,   200] training loss: 0.05654747
INFO:root:[9,   250] training loss: 0.05420713
INFO:root:[9,   300] training loss: 0.05184728
INFO:root:[9,   350] training loss: 0.04928299
INFO:root:[9,   400] training loss: 0.03496580
INFO:root:epoch9
INFO:root:[10,    50] training loss: 0.02239453
INFO:root:[10,   100] training loss: 0.03063792
INFO:root:[10,   150] training loss: 0.05388484
INFO:root:[10,   200] training loss: 0.05521679
INFO:root:[10,   250] training loss: 0.05120762
INFO:root:[10,   300] training loss: 0.05035495
INFO:root:[10,   350] training loss: 0.04909413
INFO:root:[10,   400] training loss: 0.03592984
INFO:root:epoch10
INFO:root:[11,    50] training loss: 0.02075622
INFO:root:[11,   100] training loss: 0.02960175
INFO:root:[11,   150] training loss: 0.05257953
INFO:root:[11,   200] training loss: 0.05430888
INFO:root:[11,   250] training loss: 0.04910158
INFO:root:[11,   300] training loss: 0.04928230
INFO:root:[11,   350] training loss: 0.04875690
INFO:root:[11,   400] training loss: 0.03739735
INFO:root:epoch11
INFO:root:[12,    50] training loss: 0.01972683
INFO:root:[12,   100] training loss: 0.02882165
INFO:root:[12,   150] training loss: 0.05131273
INFO:root:[12,   200] training loss: 0.05368712
INFO:root:[12,   250] training loss: 0.04705903
INFO:root:[12,   300] training loss: 0.04792206
INFO:root:[12,   350] training loss: 0.04860123
INFO:root:[12,   400] training loss: 0.03781461
INFO:root:epoch12
INFO:root:[13,    50] training loss: 0.01901738
INFO:root:[13,   100] training loss: 0.02825526
INFO:root:[13,   150] training loss: 0.04998974
INFO:root:[13,   200] training loss: 0.05276176
INFO:root:[13,   250] training loss: 0.04502643
INFO:root:[13,   300] training loss: 0.04677325
INFO:root:[13,   350] training loss: 0.04854271
INFO:root:[13,   400] training loss: 0.03846891
INFO:root:epoch13
INFO:root:[14,    50] training loss: 0.01870928
INFO:root:[14,   100] training loss: 0.02783191
INFO:root:[14,   150] training loss: 0.04886432
INFO:root:[14,   200] training loss: 0.05180882
INFO:root:[14,   250] training loss: 0.04281199
INFO:root:[14,   300] training loss: 0.04615231
INFO:root:[14,   350] training loss: 0.04838782
INFO:root:[14,   400] training loss: 0.03934587
INFO:root:epoch14
INFO:root:[15,    50] training loss: 0.01866878
INFO:root:[15,   100] training loss: 0.02866965
INFO:root:[15,   150] training loss: 0.05264042
INFO:root:[15,   200] training loss: 0.05423632
INFO:root:[15,   250] training loss: 0.04319585
INFO:root:[15,   300] training loss: 0.04754088
INFO:root:[15,   350] training loss: 0.04612747
INFO:root:[15,   400] training loss: 0.03436024
INFO:root:epoch15
INFO:root:[16,    50] training loss: 0.01817158
INFO:root:[16,   100] training loss: 0.02800942
INFO:root:[16,   150] training loss: 0.05174708
INFO:root:[16,   200] training loss: 0.05354240
INFO:root:[16,   250] training loss: 0.04263544
INFO:root:[16,   300] training loss: 0.04643818
INFO:root:[16,   350] training loss: 0.04604183
INFO:root:[16,   400] training loss: 0.03507220
INFO:root:epoch16
INFO:root:[17,    50] training loss: 0.01794612
INFO:root:[17,   100] training loss: 0.02755265
INFO:root:[17,   150] training loss: 0.05108270
INFO:root:[17,   200] training loss: 0.05313445
INFO:root:[17,   250] training loss: 0.04185043
INFO:root:[17,   300] training loss: 0.04558269
INFO:root:[17,   350] training loss: 0.04601689
INFO:root:[17,   400] training loss: 0.03595875
INFO:root:epoch17
INFO:root:[18,    50] training loss: 0.01786998
INFO:root:[18,   100] training loss: 0.02729606
INFO:root:[18,   150] training loss: 0.05071942
INFO:root:[18,   200] training loss: 0.05253651
INFO:root:[18,   250] training loss: 0.04122620
INFO:root:[18,   300] training loss: 0.04546485
INFO:root:[18,   350] training loss: 0.04620539
INFO:root:[18,   400] training loss: 0.03666780
INFO:root:epoch18
INFO:root:[19,    50] training loss: 0.01776356
INFO:root:[19,   100] training loss: 0.02702277
INFO:root:[19,   150] training loss: 0.05011104
INFO:root:[19,   200] training loss: 0.05231535
INFO:root:[19,   250] training loss: 0.04098061
INFO:root:[19,   300] training loss: 0.04555347
INFO:root:[19,   350] training loss: 0.04625118
INFO:root:[19,   400] training loss: 0.03717139
INFO:root:epoch19
INFO:root:[20,    50] training loss: 0.01762366
INFO:root:[20,   100] training loss: 0.02673978
INFO:root:[20,   150] training loss: 0.04960864
INFO:root:[20,   200] training loss: 0.05225934
INFO:root:[20,   250] training loss: 0.04060425
INFO:root:[20,   300] training loss: 0.04502820
INFO:root:[20,   350] training loss: 0.04622057
INFO:root:[20,   400] training loss: 0.03712286
INFO:root:epoch20
INFO:root:[21,    50] training loss: 0.01759349
INFO:root:[21,   100] training loss: 0.02653661
INFO:root:[21,   150] training loss: 0.04935631
INFO:root:[21,   200] training loss: 0.05204086
INFO:root:[21,   250] training loss: 0.03987847
INFO:root:[21,   300] training loss: 0.04460279
INFO:root:[21,   350] training loss: 0.04662013
INFO:root:[21,   400] training loss: 0.03728947
INFO:root:epoch21
INFO:root:[22,    50] training loss: 0.01751665
INFO:root:[22,   100] training loss: 0.02657371
INFO:root:[22,   150] training loss: 0.04937997
INFO:root:[22,   200] training loss: 0.05183673
INFO:root:[22,   250] training loss: 0.04026155
INFO:root:[22,   300] training loss: 0.04409905
INFO:root:[22,   350] training loss: 0.04596475
INFO:root:[22,   400] training loss: 0.03689525
INFO:root:epoch22
INFO:root:[23,    50] training loss: 0.01757270
INFO:root:[23,   100] training loss: 0.02634140
INFO:root:[23,   150] training loss: 0.04923772
INFO:root:[23,   200] training loss: 0.05198958
INFO:root:[23,   250] training loss: 0.03998875
INFO:root:[23,   300] training loss: 0.04482019
INFO:root:[23,   350] training loss: 0.04612737
INFO:root:[23,   400] training loss: 0.03728143
INFO:root:epoch23
INFO:root:[24,    50] training loss: 0.01754977
INFO:root:[24,   100] training loss: 0.02648707
INFO:root:[24,   150] training loss: 0.04934974
INFO:root:[24,   200] training loss: 0.05219148
INFO:root:[24,   250] training loss: 0.04025582
INFO:root:[24,   300] training loss: 0.04449313
INFO:root:[24,   350] training loss: 0.04612617
INFO:root:[24,   400] training loss: 0.03715063
INFO:root:epoch24
INFO:root:[25,    50] training loss: 0.01753006
INFO:root:[25,   100] training loss: 0.02650584
INFO:root:[25,   150] training loss: 0.04903588
INFO:root:[25,   200] training loss: 0.05197123
INFO:root:[25,   250] training loss: 0.03986802
INFO:root:[25,   300] training loss: 0.04488805
INFO:root:[25,   350] training loss: 0.04618583
INFO:root:[25,   400] training loss: 0.03677077
INFO:root:epoch25
INFO:root:[26,    50] training loss: 0.01740719
INFO:root:[26,   100] training loss: 0.02645334
INFO:root:[26,   150] training loss: 0.04921091
INFO:root:[26,   200] training loss: 0.05210662
INFO:root:[26,   250] training loss: 0.03992880
INFO:root:[26,   300] training loss: 0.04451821
INFO:root:[26,   350] training loss: 0.04638184
INFO:root:[26,   400] training loss: 0.03681797
INFO:root:epoch26
INFO:root:[27,    50] training loss: 0.01747410
INFO:root:[27,   100] training loss: 0.02643901
INFO:root:[27,   150] training loss: 0.04929987
INFO:root:[27,   200] training loss: 0.05213079
INFO:root:[27,   250] training loss: 0.03975277
INFO:root:[27,   300] training loss: 0.04448269
INFO:root:[27,   350] training loss: 0.04621151
INFO:root:[27,   400] training loss: 0.03687504
INFO:root:epoch27
INFO:root:[28,    50] training loss: 0.01754944
INFO:root:[28,   100] training loss: 0.02634532
INFO:root:[28,   150] training loss: 0.04906955
INFO:root:[28,   200] training loss: 0.05199595
INFO:root:[28,   250] training loss: 0.04010481
INFO:root:[28,   300] training loss: 0.04485778
INFO:root:[28,   350] training loss: 0.04628409
INFO:root:[28,   400] training loss: 0.03694913
INFO:root:epoch28
INFO:root:[29,    50] training loss: 0.01741969
INFO:root:[29,   100] training loss: 0.02626676
INFO:root:[29,   150] training loss: 0.04918334
INFO:root:[29,   200] training loss: 0.05216210
INFO:root:[29,   250] training loss: 0.04019384
INFO:root:[29,   300] training loss: 0.04428293
INFO:root:[29,   350] training loss: 0.04610205
INFO:root:[29,   400] training loss: 0.03716759
INFO:root:epoch29
INFO:root:[30,    50] training loss: 0.01753290
INFO:root:[30,   100] training loss: 0.02635360
INFO:root:[30,   150] training loss: 0.04928306
INFO:root:[30,   200] training loss: 0.05197546
INFO:root:[30,   250] training loss: 0.03990919
INFO:root:[30,   300] training loss: 0.04447249
INFO:root:[30,   350] training loss: 0.04614038
INFO:root:[30,   400] training loss: 0.03680627
INFO:root:epoch30
INFO:root:[31,    50] training loss: 0.01748434
INFO:root:[31,   100] training loss: 0.02632243
INFO:root:[31,   150] training loss: 0.04913549
INFO:root:[31,   200] training loss: 0.05164938
INFO:root:[31,   250] training loss: 0.03993963
INFO:root:[31,   300] training loss: 0.04436413
INFO:root:[31,   350] training loss: 0.04611251
INFO:root:[31,   400] training loss: 0.03668670
INFO:root:epoch31
INFO:root:[32,    50] training loss: 0.01750873
INFO:root:[32,   100] training loss: 0.02641109
INFO:root:[32,   150] training loss: 0.04930294
INFO:root:[32,   200] training loss: 0.05206543
INFO:root:[32,   250] training loss: 0.04032549
INFO:root:[32,   300] training loss: 0.04436899
INFO:root:[32,   350] training loss: 0.04632286
INFO:root:[32,   400] training loss: 0.03711401
INFO:root:epoch32
INFO:root:[33,    50] training loss: 0.01744469
INFO:root:[33,   100] training loss: 0.02643158
INFO:root:[33,   150] training loss: 0.04904630
INFO:root:[33,   200] training loss: 0.05205147
INFO:root:[33,   250] training loss: 0.03977714
INFO:root:[33,   300] training loss: 0.04461347
INFO:root:[33,   350] training loss: 0.04612073
INFO:root:[33,   400] training loss: 0.03686944
INFO:root:epoch33
INFO:root:[34,    50] training loss: 0.01744880
INFO:root:[34,   100] training loss: 0.02640453
INFO:root:[34,   150] training loss: 0.04902651
INFO:root:[34,   200] training loss: 0.05206961
INFO:root:[34,   250] training loss: 0.03965786
INFO:root:[34,   300] training loss: 0.04471319
INFO:root:[34,   350] training loss: 0.04608344
INFO:root:[34,   400] training loss: 0.03718898
INFO:root:epoch34
INFO:root:[35,    50] training loss: 0.01740357
INFO:root:[35,   100] training loss: 0.02633732
INFO:root:[35,   150] training loss: 0.04915021
INFO:root:[35,   200] training loss: 0.05202447
INFO:root:[35,   250] training loss: 0.04013246
INFO:root:[35,   300] training loss: 0.04422618
INFO:root:[35,   350] training loss: 0.04627202
INFO:root:[35,   400] training loss: 0.03736506
INFO:root:epoch35
INFO:root:[36,    50] training loss: 0.01741242
INFO:root:[36,   100] training loss: 0.02622763
INFO:root:[36,   150] training loss: 0.04926175
INFO:root:[36,   200] training loss: 0.05215979
INFO:root:[36,   250] training loss: 0.04028385
INFO:root:[36,   300] training loss: 0.04436375
INFO:root:[36,   350] training loss: 0.04636388
INFO:root:[36,   400] training loss: 0.03684636
INFO:root:epoch36
INFO:root:[37,    50] training loss: 0.01760908
INFO:root:[37,   100] training loss: 0.02642809
INFO:root:[37,   150] training loss: 0.04914257
INFO:root:[37,   200] training loss: 0.05184156
INFO:root:[37,   250] training loss: 0.04067864
INFO:root:[37,   300] training loss: 0.04440854
INFO:root:[37,   350] training loss: 0.04618603
INFO:root:[37,   400] training loss: 0.03725951
INFO:root:epoch37
INFO:root:[38,    50] training loss: 0.01757624
INFO:root:[38,   100] training loss: 0.02623550
INFO:root:[38,   150] training loss: 0.04915714
INFO:root:[38,   200] training loss: 0.05200608
INFO:root:[38,   250] training loss: 0.03992144
INFO:root:[38,   300] training loss: 0.04425865
INFO:root:[38,   350] training loss: 0.04609169
INFO:root:[38,   400] training loss: 0.03729849
INFO:root:epoch38
INFO:root:[39,    50] training loss: 0.01752157
INFO:root:[39,   100] training loss: 0.02631381
INFO:root:[39,   150] training loss: 0.04907893
INFO:root:[39,   200] training loss: 0.05188928
INFO:root:[39,   250] training loss: 0.03987592
INFO:root:[39,   300] training loss: 0.04430380
INFO:root:[39,   350] training loss: 0.04621727
INFO:root:[39,   400] training loss: 0.03742149
INFO:root:epoch39
INFO:root:[40,    50] training loss: 0.01753204
INFO:root:[40,   100] training loss: 0.02638053
INFO:root:[40,   150] training loss: 0.04910594
INFO:root:[40,   200] training loss: 0.05202819
INFO:root:[40,   250] training loss: 0.03961316
INFO:root:[40,   300] training loss: 0.04426840
INFO:root:[40,   350] training loss: 0.04619878
INFO:root:[40,   400] training loss: 0.03765797
INFO:root:epoch40
INFO:root:[41,    50] training loss: 0.01739996
INFO:root:[41,   100] training loss: 0.02647898
INFO:root:[41,   150] training loss: 0.04918060
INFO:root:[41,   200] training loss: 0.05171712
INFO:root:[41,   250] training loss: 0.04026504
INFO:root:[41,   300] training loss: 0.04416509
INFO:root:[41,   350] training loss: 0.04616817
INFO:root:[41,   400] training loss: 0.03753378
INFO:root:epoch41
INFO:root:[42,    50] training loss: 0.01770242
INFO:root:[42,   100] training loss: 0.02637507
INFO:root:[42,   150] training loss: 0.04906554
INFO:root:[42,   200] training loss: 0.05227681
INFO:root:[42,   250] training loss: 0.03983425
INFO:root:[42,   300] training loss: 0.04441471
INFO:root:[42,   350] training loss: 0.04613412
INFO:root:[42,   400] training loss: 0.03725291
INFO:root:epoch42
INFO:root:[43,    50] training loss: 0.01752142
INFO:root:[43,   100] training loss: 0.02646158
INFO:root:[43,   150] training loss: 0.04916286
INFO:root:[43,   200] training loss: 0.05205006
INFO:root:[43,   250] training loss: 0.04020634
INFO:root:[43,   300] training loss: 0.04446783
INFO:root:[43,   350] training loss: 0.04613416
INFO:root:[43,   400] training loss: 0.03745953
INFO:root:epoch43
INFO:root:[44,    50] training loss: 0.01742280
INFO:root:[44,   100] training loss: 0.02648847
INFO:root:[44,   150] training loss: 0.04905034
INFO:root:[44,   200] training loss: 0.05191992
INFO:root:[44,   250] training loss: 0.04037159
INFO:root:[44,   300] training loss: 0.04472781
INFO:root:[44,   350] training loss: 0.04618728
INFO:root:[44,   400] training loss: 0.03704043
INFO:root:epoch44
INFO:root:[45,    50] training loss: 0.01738074
INFO:root:[45,   100] training loss: 0.02620227
INFO:root:[45,   150] training loss: 0.04910709
INFO:root:[45,   200] training loss: 0.05187879
INFO:root:[45,   250] training loss: 0.04041854
INFO:root:[45,   300] training loss: 0.04433600
INFO:root:[45,   350] training loss: 0.04620421
INFO:root:[45,   400] training loss: 0.03699363
INFO:root:epoch45
INFO:root:[46,    50] training loss: 0.01747725
INFO:root:[46,   100] training loss: 0.02638148
INFO:root:[46,   150] training loss: 0.04905019
INFO:root:[46,   200] training loss: 0.05168427
INFO:root:[46,   250] training loss: 0.04015088
INFO:root:[46,   300] training loss: 0.04456105
INFO:root:[46,   350] training loss: 0.04632617
INFO:root:[46,   400] training loss: 0.03726527
INFO:root:epoch46
INFO:root:[47,    50] training loss: 0.01744004
INFO:root:[47,   100] training loss: 0.02643185
INFO:root:[47,   150] training loss: 0.04927490
INFO:root:[47,   200] training loss: 0.05193504
INFO:root:[47,   250] training loss: 0.03938862
INFO:root:[47,   300] training loss: 0.04449569
INFO:root:[47,   350] training loss: 0.04605313
INFO:root:[47,   400] training loss: 0.03759658
INFO:root:epoch47
INFO:root:[48,    50] training loss: 0.01748310
INFO:root:[48,   100] training loss: 0.02632413
INFO:root:[48,   150] training loss: 0.04902182
INFO:root:[48,   200] training loss: 0.05196784
INFO:root:[48,   250] training loss: 0.03958377
INFO:root:[48,   300] training loss: 0.04456288
INFO:root:[48,   350] training loss: 0.04623817
INFO:root:[48,   400] training loss: 0.03749358
INFO:root:epoch48
INFO:root:[49,    50] training loss: 0.01746078
INFO:root:[49,   100] training loss: 0.02629814
INFO:root:[49,   150] training loss: 0.04921015
INFO:root:[49,   200] training loss: 0.05193424
INFO:root:[49,   250] training loss: 0.04003138
INFO:root:[49,   300] training loss: 0.04461534
INFO:root:[49,   350] training loss: 0.04624214
INFO:root:[49,   400] training loss: 0.03688922
INFO:root:epoch49
INFO:root:[50,    50] training loss: 0.01751374
INFO:root:[50,   100] training loss: 0.02636717
INFO:root:[50,   150] training loss: 0.04907803
INFO:root:[50,   200] training loss: 0.05221034
INFO:root:[50,   250] training loss: 0.04004724
INFO:root:[50,   300] training loss: 0.04430324
INFO:root:[50,   350] training loss: 0.04606443
INFO:root:[50,   400] training loss: 0.03741331
INFO:root:Finished Training
INFO:root:Accuracy of the network on the 6256 test images: 77 %
INFO:root:                   precision    recall  f1-score   support

          unknown     0.1667    0.1212    0.1404       264
           CD4+ T     0.5441    0.8521    0.6642       933
           CD8+ T     0.2667    0.0217    0.0401       369
 CD15+ neutrophil     0.9522    0.9923    0.9718      3634
   CD14+ monocyte     0.3365    0.7303    0.4607       241
          CD19+ B     0.1667    0.0050    0.0096       202
         CD56+ NK     0.0000    0.0000    0.0000       127
              NKT     0.0000    0.0000    0.0000       206
       eosinophil     0.8933    0.8071    0.8480       280

         accuracy                         0.7743      6256
        macro avg     0.3696    0.3922    0.3483      6256
     weighted avg     0.7154    0.7743    0.7279      6256

INFO:root:    unknown   CD4+ T   CD8+ T   CD15+ neutrophil   CD14+ monocyte   CD19+ B   CD56+ NK   NKT   eosinophil
0  0.140351  0.66416   0.0401           0.971837         0.460733  0.009615        0.0   0.0      0.84803
INFO:root:statistics used: {'mean': tensor([0.1728, 0.1691]), 'std': tensor([0.0640, 0.0626])}
INFO:root:train dataset: 131697, test dataset: 6256
INFO:root:used only channels: [0, 8]; only classes: None
INFO:root:epoch0
INFO:root:[1,    50] training loss: 0.03971721
INFO:root:[1,   100] training loss: 0.03965816
INFO:root:[1,   150] training loss: 0.05395903
INFO:root:[1,   200] training loss: 0.06337449
INFO:root:[1,   250] training loss: 0.06739320
INFO:root:[1,   300] training loss: 0.05975326
INFO:root:[1,   350] training loss: 0.06081323
INFO:root:[1,   400] training loss: 0.07181514
INFO:root:epoch1
INFO:root:[2,    50] training loss: 0.03898961
INFO:root:[2,   100] training loss: 0.03764843
INFO:root:[2,   150] training loss: 0.04676872
INFO:root:[2,   200] training loss: 0.05334412
INFO:root:[2,   250] training loss: 0.05356489
INFO:root:[2,   300] training loss: 0.05347047
INFO:root:[2,   350] training loss: 0.05785379
INFO:root:[2,   400] training loss: 0.06351666
INFO:root:epoch2
INFO:root:[3,    50] training loss: 0.03409687
INFO:root:[3,   100] training loss: 0.03447826
INFO:root:[3,   150] training loss: 0.04548290
INFO:root:[3,   200] training loss: 0.04923367
INFO:root:[3,   250] training loss: 0.05394936
INFO:root:[3,   300] training loss: 0.05304092
INFO:root:[3,   350] training loss: 0.05805373
INFO:root:[3,   400] training loss: 0.06073573
INFO:root:epoch3
INFO:root:[4,    50] training loss: 0.03085156
INFO:root:[4,   100] training loss: 0.03377696
INFO:root:[4,   150] training loss: 0.04774964
INFO:root:[4,   200] training loss: 0.05051972
INFO:root:[4,   250] training loss: 0.05234201
INFO:root:[4,   300] training loss: 0.04881684
INFO:root:[4,   350] training loss: 0.05432451
INFO:root:[4,   400] training loss: 0.05977086
INFO:root:epoch4
INFO:root:[5,    50] training loss: 0.03075995
INFO:root:[5,   100] training loss: 0.03167517
INFO:root:[5,   150] training loss: 0.04748815
INFO:root:[5,   200] training loss: 0.05234399
INFO:root:[5,   250] training loss: 0.05108527
INFO:root:[5,   300] training loss: 0.04864884
INFO:root:[5,   350] training loss: 0.04963491
INFO:root:[5,   400] training loss: 0.05050631
INFO:root:epoch5
INFO:root:[6,    50] training loss: 0.02485499
INFO:root:[6,   100] training loss: 0.02967816
INFO:root:[6,   150] training loss: 0.04446956
INFO:root:[6,   200] training loss: 0.04938132
INFO:root:[6,   250] training loss: 0.04750230
INFO:root:[6,   300] training loss: 0.04678805
INFO:root:[6,   350] training loss: 0.04885184
INFO:root:[6,   400] training loss: 0.05394554
INFO:root:epoch6
INFO:root:[7,    50] training loss: 0.02387503
INFO:root:[7,   100] training loss: 0.02845540
INFO:root:[7,   150] training loss: 0.04165983
INFO:root:[7,   200] training loss: 0.04586975
INFO:root:[7,   250] training loss: 0.04239687
INFO:root:[7,   300] training loss: 0.04618774
INFO:root:[7,   350] training loss: 0.04495740
INFO:root:[7,   400] training loss: 0.04237082
INFO:root:epoch7
INFO:root:[8,    50] training loss: 0.04314457
INFO:root:[8,   100] training loss: 0.03846138
INFO:root:[8,   150] training loss: 0.06556173
INFO:root:[8,   200] training loss: 0.06238780
INFO:root:[8,   250] training loss: 0.05299468
INFO:root:[8,   300] training loss: 0.04933877
INFO:root:[8,   350] training loss: 0.04508588
INFO:root:[8,   400] training loss: 0.03551847
INFO:root:epoch8
INFO:root:[9,    50] training loss: 0.02005931
INFO:root:[9,   100] training loss: 0.03233315
INFO:root:[9,   150] training loss: 0.06016796
INFO:root:[9,   200] training loss: 0.06116058
INFO:root:[9,   250] training loss: 0.04623072
INFO:root:[9,   300] training loss: 0.04458246
INFO:root:[9,   350] training loss: 0.04459629
INFO:root:[9,   400] training loss: 0.03635267
INFO:root:epoch9
INFO:root:[10,    50] training loss: 0.01867915
INFO:root:[10,   100] training loss: 0.03129354
INFO:root:[10,   150] training loss: 0.05855230
INFO:root:[10,   200] training loss: 0.05934142
INFO:root:[10,   250] training loss: 0.04323871
INFO:root:[10,   300] training loss: 0.04359108
INFO:root:[10,   350] training loss: 0.04487228
INFO:root:[10,   400] training loss: 0.03739614
INFO:root:epoch10
INFO:root:[11,    50] training loss: 0.01807317
INFO:root:[11,   100] training loss: 0.03047367
INFO:root:[11,   150] training loss: 0.05710927
INFO:root:[11,   200] training loss: 0.05801551
INFO:root:[11,   250] training loss: 0.04119040
INFO:root:[11,   300] training loss: 0.04291908
INFO:root:[11,   350] training loss: 0.04485298
INFO:root:[11,   400] training loss: 0.03639365
INFO:root:epoch11
INFO:root:[12,    50] training loss: 0.01745841
INFO:root:[12,   100] training loss: 0.02949825
INFO:root:[12,   150] training loss: 0.05544831
INFO:root:[12,   200] training loss: 0.05676676
INFO:root:[12,   250] training loss: 0.03967684
INFO:root:[12,   300] training loss: 0.04307875
INFO:root:[12,   350] training loss: 0.04559081
INFO:root:[12,   400] training loss: 0.03636410
INFO:root:epoch12
INFO:root:[13,    50] training loss: 0.01726501
INFO:root:[13,   100] training loss: 0.02865867
INFO:root:[13,   150] training loss: 0.05407092
INFO:root:[13,   200] training loss: 0.05581402
INFO:root:[13,   250] training loss: 0.03827831
INFO:root:[13,   300] training loss: 0.04215531
INFO:root:[13,   350] training loss: 0.04499007
INFO:root:[13,   400] training loss: 0.03678033
INFO:root:epoch13
INFO:root:[14,    50] training loss: 0.01698787
INFO:root:[14,   100] training loss: 0.02814803
INFO:root:[14,   150] training loss: 0.05298261
INFO:root:[14,   200] training loss: 0.05502749
INFO:root:[14,   250] training loss: 0.03739012
INFO:root:[14,   300] training loss: 0.04211254
INFO:root:[14,   350] training loss: 0.04501888
INFO:root:[14,   400] training loss: 0.03652297
INFO:root:epoch14
INFO:root:[15,    50] training loss: 0.01702572
INFO:root:[15,   100] training loss: 0.02812155
INFO:root:[15,   150] training loss: 0.05487206
INFO:root:[15,   200] training loss: 0.05566317
INFO:root:[15,   250] training loss: 0.03973115
INFO:root:[15,   300] training loss: 0.04316943
INFO:root:[15,   350] training loss: 0.04359359
INFO:root:[15,   400] training loss: 0.03353013
INFO:root:epoch15
INFO:root:[16,    50] training loss: 0.01669635
INFO:root:[16,   100] training loss: 0.02746453
INFO:root:[16,   150] training loss: 0.05388141
INFO:root:[16,   200] training loss: 0.05537201
INFO:root:[16,   250] training loss: 0.03830345
INFO:root:[16,   300] training loss: 0.04242714
INFO:root:[16,   350] training loss: 0.04385204
INFO:root:[16,   400] training loss: 0.03446014
INFO:root:epoch16
INFO:root:[17,    50] training loss: 0.01679150
INFO:root:[17,   100] training loss: 0.02703264
INFO:root:[17,   150] training loss: 0.05342803
INFO:root:[17,   200] training loss: 0.05527267
INFO:root:[17,   250] training loss: 0.03669771
INFO:root:[17,   300] training loss: 0.04113672
INFO:root:[17,   350] training loss: 0.04407108
INFO:root:[17,   400] training loss: 0.03480415
INFO:root:epoch17
INFO:root:[18,    50] training loss: 0.01671394
INFO:root:[18,   100] training loss: 0.02669384
INFO:root:[18,   150] training loss: 0.05274524
INFO:root:[18,   200] training loss: 0.05496243
INFO:root:[18,   250] training loss: 0.03666087
INFO:root:[18,   300] training loss: 0.04090479
INFO:root:[18,   350] training loss: 0.04402760
INFO:root:[18,   400] training loss: 0.03540669
INFO:root:epoch18
INFO:root:[19,    50] training loss: 0.01672315
INFO:root:[19,   100] training loss: 0.02630124
INFO:root:[19,   150] training loss: 0.05239908
INFO:root:[19,   200] training loss: 0.05501145
INFO:root:[19,   250] training loss: 0.03589963
INFO:root:[19,   300] training loss: 0.04100737
INFO:root:[19,   350] training loss: 0.04391292
INFO:root:[19,   400] training loss: 0.03557368
INFO:root:epoch19
INFO:root:[20,    50] training loss: 0.01667806
INFO:root:[20,   100] training loss: 0.02631726
INFO:root:[20,   150] training loss: 0.05194373
INFO:root:[20,   200] training loss: 0.05477611
INFO:root:[20,   250] training loss: 0.03560228
INFO:root:[20,   300] training loss: 0.04084762
INFO:root:[20,   350] training loss: 0.04390299
INFO:root:[20,   400] training loss: 0.03541531
INFO:root:epoch20
INFO:root:[21,    50] training loss: 0.01668413
INFO:root:[21,   100] training loss: 0.02603310
INFO:root:[21,   150] training loss: 0.05174860
INFO:root:[21,   200] training loss: 0.05471255
INFO:root:[21,   250] training loss: 0.03575371
INFO:root:[21,   300] training loss: 0.04029268
INFO:root:[21,   350] training loss: 0.04432101
INFO:root:[21,   400] training loss: 0.03596152
INFO:root:epoch21
INFO:root:[22,    50] training loss: 0.01661796
INFO:root:[22,   100] training loss: 0.02607258
INFO:root:[22,   150] training loss: 0.05179834
INFO:root:[22,   200] training loss: 0.05456218
INFO:root:[22,   250] training loss: 0.03544057
INFO:root:[22,   300] training loss: 0.04094347
INFO:root:[22,   350] training loss: 0.04384790
INFO:root:[22,   400] training loss: 0.03517397
INFO:root:epoch22
INFO:root:[23,    50] training loss: 0.01655338
INFO:root:[23,   100] training loss: 0.02602228
INFO:root:[23,   150] training loss: 0.05209640
INFO:root:[23,   200] training loss: 0.05467043
INFO:root:[23,   250] training loss: 0.03534571
INFO:root:[23,   300] training loss: 0.04064250
INFO:root:[23,   350] training loss: 0.04388952
INFO:root:[23,   400] training loss: 0.03518180
INFO:root:epoch23
INFO:root:[24,    50] training loss: 0.01663396
INFO:root:[24,   100] training loss: 0.02593459
INFO:root:[24,   150] training loss: 0.05173524
INFO:root:[24,   200] training loss: 0.05475894
INFO:root:[24,   250] training loss: 0.03524391
INFO:root:[24,   300] training loss: 0.04065410
INFO:root:[24,   350] training loss: 0.04386775
INFO:root:[24,   400] training loss: 0.03542260
INFO:root:epoch24
INFO:root:[25,    50] training loss: 0.01660602
INFO:root:[25,   100] training loss: 0.02596556
INFO:root:[25,   150] training loss: 0.05168478
INFO:root:[25,   200] training loss: 0.05474313
INFO:root:[25,   250] training loss: 0.03560253
INFO:root:[25,   300] training loss: 0.04062708
INFO:root:[25,   350] training loss: 0.04374319
INFO:root:[25,   400] training loss: 0.03514213
INFO:root:epoch25
INFO:root:[26,    50] training loss: 0.01660605
INFO:root:[26,   100] training loss: 0.02604492
INFO:root:[26,   150] training loss: 0.05167566
INFO:root:[26,   200] training loss: 0.05481948
INFO:root:[26,   250] training loss: 0.03533627
INFO:root:[26,   300] training loss: 0.04083565
INFO:root:[26,   350] training loss: 0.04374216
INFO:root:[26,   400] training loss: 0.03553619
INFO:root:epoch26
INFO:root:[27,    50] training loss: 0.01664515
INFO:root:[27,   100] training loss: 0.02592379
INFO:root:[27,   150] training loss: 0.05169288
INFO:root:[27,   200] training loss: 0.05467025
INFO:root:[27,   250] training loss: 0.03507634
INFO:root:[27,   300] training loss: 0.04070858
INFO:root:[27,   350] training loss: 0.04339470
INFO:root:[27,   400] training loss: 0.03546662
INFO:root:epoch27
INFO:root:[28,    50] training loss: 0.01663845
INFO:root:[28,   100] training loss: 0.02594741
INFO:root:[28,   150] training loss: 0.05156264
INFO:root:[28,   200] training loss: 0.05461629
INFO:root:[28,   250] training loss: 0.03564189
INFO:root:[28,   300] training loss: 0.04019412
INFO:root:[28,   350] training loss: 0.04367072
INFO:root:[28,   400] training loss: 0.03585579
INFO:root:epoch28
INFO:root:[29,    50] training loss: 0.01653068
INFO:root:[29,   100] training loss: 0.02597727
INFO:root:[29,   150] training loss: 0.05157229
INFO:root:[29,   200] training loss: 0.05464103
INFO:root:[29,   250] training loss: 0.03522050
INFO:root:[29,   300] training loss: 0.04072382
INFO:root:[29,   350] training loss: 0.04404435
INFO:root:[29,   400] training loss: 0.03557791
INFO:root:epoch29
INFO:root:[30,    50] training loss: 0.01669384
INFO:root:[30,   100] training loss: 0.02593717
INFO:root:[30,   150] training loss: 0.05159237
INFO:root:[30,   200] training loss: 0.05453424
INFO:root:[30,   250] training loss: 0.03497544
INFO:root:[30,   300] training loss: 0.04036762
INFO:root:[30,   350] training loss: 0.04404040
INFO:root:[30,   400] training loss: 0.03544966
INFO:root:epoch30
INFO:root:[31,    50] training loss: 0.01664404
INFO:root:[31,   100] training loss: 0.02605970
INFO:root:[31,   150] training loss: 0.05164901
INFO:root:[31,   200] training loss: 0.05450970
INFO:root:[31,   250] training loss: 0.03540385
INFO:root:[31,   300] training loss: 0.04037701
INFO:root:[31,   350] training loss: 0.04409427
INFO:root:[31,   400] training loss: 0.03515828
INFO:root:epoch31
INFO:root:[32,    50] training loss: 0.01662301
INFO:root:[32,   100] training loss: 0.02601844
INFO:root:[32,   150] training loss: 0.05173521
INFO:root:[32,   200] training loss: 0.05462588
INFO:root:[32,   250] training loss: 0.03493408
INFO:root:[32,   300] training loss: 0.04052097
INFO:root:[32,   350] training loss: 0.04345381
INFO:root:[32,   400] training loss: 0.03517052
INFO:root:epoch32
INFO:root:[33,    50] training loss: 0.01657922
INFO:root:[33,   100] training loss: 0.02591827
INFO:root:[33,   150] training loss: 0.05170135
INFO:root:[33,   200] training loss: 0.05456116
INFO:root:[33,   250] training loss: 0.03527126
INFO:root:[33,   300] training loss: 0.04088381
INFO:root:[33,   350] training loss: 0.04369947
INFO:root:[33,   400] training loss: 0.03516740
INFO:root:epoch33
INFO:root:[34,    50] training loss: 0.01671751
INFO:root:[34,   100] training loss: 0.02592436
INFO:root:[34,   150] training loss: 0.05160845
INFO:root:[34,   200] training loss: 0.05451641
INFO:root:[34,   250] training loss: 0.03500933
INFO:root:[34,   300] training loss: 0.04022031
INFO:root:[34,   350] training loss: 0.04403676
INFO:root:[34,   400] training loss: 0.03559011
INFO:root:epoch34
INFO:root:[35,    50] training loss: 0.01664835
INFO:root:[35,   100] training loss: 0.02584635
INFO:root:[35,   150] training loss: 0.05158837
INFO:root:[35,   200] training loss: 0.05461730
INFO:root:[35,   250] training loss: 0.03564364
INFO:root:[35,   300] training loss: 0.04017936
INFO:root:[35,   350] training loss: 0.04398643
INFO:root:[35,   400] training loss: 0.03536321
INFO:root:epoch35
INFO:root:[36,    50] training loss: 0.01660510
INFO:root:[36,   100] training loss: 0.02582241
INFO:root:[36,   150] training loss: 0.05182309
INFO:root:[36,   200] training loss: 0.05457757
INFO:root:[36,   250] training loss: 0.03530648
INFO:root:[36,   300] training loss: 0.04056315
INFO:root:[36,   350] training loss: 0.04377086
INFO:root:[36,   400] training loss: 0.03543515
INFO:root:epoch36
INFO:root:[37,    50] training loss: 0.01663818
INFO:root:[37,   100] training loss: 0.02591916
INFO:root:[37,   150] training loss: 0.05160988
INFO:root:[37,   200] training loss: 0.05456532
INFO:root:[37,   250] training loss: 0.03529680
INFO:root:[37,   300] training loss: 0.04051841
INFO:root:[37,   350] training loss: 0.04407127
INFO:root:[37,   400] training loss: 0.03570286
INFO:root:epoch37
INFO:root:[38,    50] training loss: 0.01656972
INFO:root:[38,   100] training loss: 0.02597986
INFO:root:[38,   150] training loss: 0.05161234
INFO:root:[38,   200] training loss: 0.05471303
INFO:root:[38,   250] training loss: 0.03568491
INFO:root:[38,   300] training loss: 0.04039395
INFO:root:[38,   350] training loss: 0.04400584
INFO:root:[38,   400] training loss: 0.03611584
INFO:root:epoch38
INFO:root:[39,    50] training loss: 0.01660816
INFO:root:[39,   100] training loss: 0.02579078
INFO:root:[39,   150] training loss: 0.05160118
INFO:root:[39,   200] training loss: 0.05458891
INFO:root:[39,   250] training loss: 0.03524756
INFO:root:[39,   300] training loss: 0.04004997
INFO:root:[39,   350] training loss: 0.04403905
INFO:root:[39,   400] training loss: 0.03543202
INFO:root:epoch39
INFO:root:[40,    50] training loss: 0.01664307
INFO:root:[40,   100] training loss: 0.02579738
INFO:root:[40,   150] training loss: 0.05171251
INFO:root:[40,   200] training loss: 0.05475356
INFO:root:[40,   250] training loss: 0.03529741
INFO:root:[40,   300] training loss: 0.04069166
INFO:root:[40,   350] training loss: 0.04367014
INFO:root:[40,   400] training loss: 0.03530558
INFO:root:epoch40
INFO:root:[41,    50] training loss: 0.01662507
INFO:root:[41,   100] training loss: 0.02586657
INFO:root:[41,   150] training loss: 0.05162307
INFO:root:[41,   200] training loss: 0.05446912
INFO:root:[41,   250] training loss: 0.03552116
INFO:root:[41,   300] training loss: 0.04037023
INFO:root:[41,   350] training loss: 0.04415294
INFO:root:[41,   400] training loss: 0.03591280
INFO:root:epoch41
INFO:root:[42,    50] training loss: 0.01663547
INFO:root:[42,   100] training loss: 0.02594607
INFO:root:[42,   150] training loss: 0.05160315
INFO:root:[42,   200] training loss: 0.05465576
INFO:root:[42,   250] training loss: 0.03537240
INFO:root:[42,   300] training loss: 0.04049386
INFO:root:[42,   350] training loss: 0.04366003
INFO:root:[42,   400] training loss: 0.03541132
INFO:root:epoch42
INFO:root:[43,    50] training loss: 0.01656713
INFO:root:[43,   100] training loss: 0.02606959
INFO:root:[43,   150] training loss: 0.05173100
INFO:root:[43,   200] training loss: 0.05457141
INFO:root:[43,   250] training loss: 0.03520175
INFO:root:[43,   300] training loss: 0.04072540
INFO:root:[43,   350] training loss: 0.04365356
INFO:root:[43,   400] training loss: 0.03542787
INFO:root:epoch43
INFO:root:[44,    50] training loss: 0.01663976
INFO:root:[44,   100] training loss: 0.02579066
INFO:root:[44,   150] training loss: 0.05151203
INFO:root:[44,   200] training loss: 0.05453805
INFO:root:[44,   250] training loss: 0.03559827
INFO:root:[44,   300] training loss: 0.04069014
INFO:root:[44,   350] training loss: 0.04378894
INFO:root:[44,   400] training loss: 0.03594388
INFO:root:epoch44
INFO:root:[45,    50] training loss: 0.01657870
INFO:root:[45,   100] training loss: 0.02618904
INFO:root:[45,   150] training loss: 0.05143625
INFO:root:[45,   200] training loss: 0.05470331
INFO:root:[45,   250] training loss: 0.03489384
INFO:root:[45,   300] training loss: 0.04042576
INFO:root:[45,   350] training loss: 0.04378312
INFO:root:[45,   400] training loss: 0.03522630
INFO:root:epoch45
INFO:root:[46,    50] training loss: 0.01656422
INFO:root:[46,   100] training loss: 0.02574027
INFO:root:[46,   150] training loss: 0.05163420
INFO:root:[46,   200] training loss: 0.05476225
INFO:root:[46,   250] training loss: 0.03540130
INFO:root:[46,   300] training loss: 0.04012563
INFO:root:[46,   350] training loss: 0.04396546
INFO:root:[46,   400] training loss: 0.03523388
INFO:root:epoch46
INFO:root:[47,    50] training loss: 0.01656506
INFO:root:[47,   100] training loss: 0.02594037
INFO:root:[47,   150] training loss: 0.05159820
INFO:root:[47,   200] training loss: 0.05485919
INFO:root:[47,   250] training loss: 0.03556079
INFO:root:[47,   300] training loss: 0.04089388
INFO:root:[47,   350] training loss: 0.04362294
INFO:root:[47,   400] training loss: 0.03548889
INFO:root:epoch47
INFO:root:[48,    50] training loss: 0.01664411
INFO:root:[48,   100] training loss: 0.02615636
INFO:root:[48,   150] training loss: 0.05152328
INFO:root:[48,   200] training loss: 0.05452766
INFO:root:[48,   250] training loss: 0.03542553
INFO:root:[48,   300] training loss: 0.04104690
INFO:root:[48,   350] training loss: 0.04369319
INFO:root:[48,   400] training loss: 0.03503093
INFO:root:epoch48
INFO:root:[49,    50] training loss: 0.01656151
INFO:root:[49,   100] training loss: 0.02570332
INFO:root:[49,   150] training loss: 0.05151686
INFO:root:[49,   200] training loss: 0.05449166
INFO:root:[49,   250] training loss: 0.03558588
INFO:root:[49,   300] training loss: 0.04039544
INFO:root:[49,   350] training loss: 0.04383086
INFO:root:[49,   400] training loss: 0.03522349
INFO:root:epoch49
INFO:root:[50,    50] training loss: 0.01653270
INFO:root:[50,   100] training loss: 0.02602907
INFO:root:[50,   150] training loss: 0.05179188
INFO:root:[50,   200] training loss: 0.05466520
INFO:root:[50,   250] training loss: 0.03550629
INFO:root:[50,   300] training loss: 0.04093978
INFO:root:[50,   350] training loss: 0.04402013
INFO:root:[50,   400] training loss: 0.03514584
INFO:root:Finished Training
INFO:root:Accuracy of the network on the 6256 test images: 77 %
INFO:root:                   precision    recall  f1-score   support

          unknown     0.1642    0.0837    0.1108       263
           CD4+ T     0.5329    0.8512    0.6555       894
           CD8+ T     0.2250    0.0544    0.0876       331
 CD15+ neutrophil     0.9527    0.9767    0.9646      3692
   CD14+ monocyte     0.4706    0.7605    0.5814       263
          CD19+ B     0.0000    0.0000    0.0000       174
         CD56+ NK     0.0000    0.0000    0.0000       133
              NKT     0.1250    0.0101    0.0186       199
       eosinophil     0.6719    0.8339    0.7442       307

         accuracy                         0.7777      6256
        macro avg     0.3491    0.3967    0.3514      6256
     weighted avg     0.7139    0.7777    0.7338      6256

INFO:root:    unknown    CD4+ T    CD8+ T   CD15+ neutrophil   CD14+ monocyte   CD19+ B   CD56+ NK       NKT   eosinophil
0  0.110831  0.655469  0.087591           0.964558         0.581395       0.0        0.0  0.018605     0.744186
