{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9399e516-61fb-4f4f-93ff-38a582157f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import Tracer\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import os\n",
    "import time\n",
    "import multiprocessing\n",
    "import psutil\n",
    "import json\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd  \n",
    "import h5py\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.util import crop,  random_noise\n",
    "from skimage.transform import   rescale, resize, rotate, AffineTransform, warp\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from resnet18 import resnet18\n",
    "from collections import Counter\n",
    "from util import get_statistics\n",
    "from dataset import Dataset_Generator, train_validation_test_split, get_classes_map, number_of_classes, number_of_channels, get_all_object_numbers_labels\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "88fea5de-24d8-4712-917b-40cec68b0753",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 300\n",
    "n_epochs = 100\n",
    "num_workers = 0\n",
    "lr = 0.001\n",
    "n_splits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74784265-e827-4baa-a636-0cc79643c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "only_channels = [0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
    "only_classes = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "105917ed-b578-4d8b-982a-f520ea4ab00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_file = \"data/WBC/Lyse fix sample_1_Focused & Singlets & CD45 pos.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dda7028d-dcff-4d0b-953a-d868dda809b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = get_classes_map(h5_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f1609f74-f717-45d1-98e2-dad53fbb1749",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = list(label_map.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9d790351-a1cb-4057-8cc5-ea9be212d57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1., p=0.5):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        self.p = p\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        if torch.rand(1) < self.p:\n",
    "            return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "        return tensor\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9f0b795-aa7d-4f26-84f8-e35500d45ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "        [transforms.RandomVerticalFlip(),\n",
    "         transforms.RandomHorizontalFlip(),\n",
    "         transforms.RandomRotation(45),\n",
    "        AddGaussianNoise(0., 1., 0.3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "57c49064-5db0-473a-bb76-f0421f296c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = number_of_classes(h5_file, only_classes=only_classes)\n",
    "num_channels = number_of_channels(h5_file, only_channels=only_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9724457f-8145-4fca-a81a-ec43fae561e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42, sampling_strategy='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "dc7115b7-c2ee-49bb-b31f-d5bf742ce419",
   "metadata": {},
   "outputs": [],
   "source": [
    "class oversampled_Kfold():\n",
    "    def __init__(self, n_splits, n_repeats=1):\n",
    "        self.n_splits = n_splits\n",
    "        self.n_repeats = n_repeats\n",
    "\n",
    "    def get_n_splits(self, X, y, groups=None):\n",
    "        return self.n_splits*self.n_repeats\n",
    "\n",
    "    def split(self, X, y, groups=None):\n",
    "        splits = np.array_split(np.random.choice(len(X), len(X),replace=False), self.n_splits)\n",
    "        train, test = [], []\n",
    "        for repeat in range(self.n_repeats):\n",
    "            for idx in range(len(splits)):\n",
    "                trainingIdx = np.delete(splits, idx)\n",
    "                Xidx_r, y_r = ros.fit_resample(np.hstack(trainingIdx).reshape((-1,1)), np.asarray(y[np.hstack(trainingIdx)]))\n",
    "                train.append(Xidx_r.flatten())\n",
    "                test.append(splits[idx])\n",
    "        return list(zip(train, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8a38b549-6476-4f51-b07a-bc526de278fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rkf_search = oversampled_Kfold(n_splits=n_splits, n_repeats=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ea7a7b1d-e0af-4eab-88d8-41f6517c8e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_all_object_numbers_labels(h5_file, only_classes) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7e7d4c7b-9fa2-455c-b538-5aeb899fc694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start validation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexa\\anaconda3\\envs\\interai\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "C:\\Users\\Alexa\\anaconda3\\envs\\interai\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n",
      "C:\\Users\\Alexa\\anaconda3\\envs\\interai\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0\n",
      "epoch1\n",
      "epoch2\n",
      "epoch3\n",
      "epoch4\n",
      "Accuracy of the network on the 10427 test images: 5 %\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "          unknown     0.0000    0.0000    0.0000       412\n",
      "           CD4+ T     1.0000    0.0035    0.0070      1428\n",
      "           CD8+ T     0.0000    0.0000    0.0000       615\n",
      " CD15+ neutrophil     0.0000    0.0000    0.0000      6103\n",
      "   CD14+ monocyte     0.0000    0.0000    0.0000       445\n",
      "          CD19+ B     0.0000    0.0000    0.0000       318\n",
      "         CD56+ NK     0.0000    0.0000    0.0000       230\n",
      "              NKT     0.0000    0.0000    0.0000       331\n",
      "       eosinophil     0.0523    1.0000    0.0994       545\n",
      "\n",
      "         accuracy                         0.0527     10427\n",
      "        macro avg     0.1169    0.1115    0.0118     10427\n",
      "     weighted avg     0.1397    0.0527    0.0062     10427\n",
      "\n",
      "    unknown    CD4+ T   CD8+ T   CD15+ neutrophil   CD14+ monocyte   CD19+ B   CD56+ NK   NKT   eosinophil\n",
      "0       0.0  0.006978      0.0                0.0              0.0       0.0        0.0   0.0     0.099389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexa\\anaconda3\\envs\\interai\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Alexa\\anaconda3\\envs\\interai\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Alexa\\anaconda3\\envs\\interai\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0\n",
      "epoch1\n",
      "epoch2\n",
      "epoch3\n",
      "epoch4\n",
      "Accuracy of the network on the 10427 test images: 6 %\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "          unknown     0.0000    0.0000    0.0000       414\n",
      "           CD4+ T     0.9839    0.0404    0.0777      1509\n",
      "           CD8+ T     0.8421    0.0530    0.0997       604\n",
      " CD15+ neutrophil     1.0000    0.0003    0.0006      6163\n",
      "   CD14+ monocyte     0.0000    0.0000    0.0000       423\n",
      "          CD19+ B     0.0000    0.0000    0.0000       287\n",
      "         CD56+ NK     0.0000    0.0000    0.0000       203\n",
      "              NKT     0.2079    0.1775    0.1915       355\n",
      "       eosinophil     0.0468    1.0000    0.0894       469\n",
      "\n",
      "         accuracy                         0.0601     10427\n",
      "        macro avg     0.3423    0.1412    0.0510     10427\n",
      "     weighted avg     0.7914    0.0601    0.0279     10427\n",
      "\n",
      "    unknown    CD4+ T    CD8+ T   CD15+ neutrophil   CD14+ monocyte   CD19+ B   CD56+ NK       NKT   eosinophil\n",
      "0       0.0  0.077658  0.099688           0.000649              0.0       0.0        0.0  0.191489      0.08941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexa\\anaconda3\\envs\\interai\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Alexa\\anaconda3\\envs\\interai\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Alexa\\anaconda3\\envs\\interai\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch0\n",
      "epoch1\n",
      "epoch2\n",
      "epoch3\n",
      "epoch4\n",
      "Accuracy of the network on the 10426 test images: 5 %\n",
      "                   precision    recall  f1-score   support\n",
      "\n",
      "          unknown     0.0000    0.0000    0.0000       460\n",
      "           CD4+ T     0.0000    0.0000    0.0000      1539\n",
      "           CD8+ T     0.0000    0.0000    0.0000       569\n",
      " CD15+ neutrophil     0.0000    0.0000    0.0000      6059\n",
      "   CD14+ monocyte     0.0000    0.0000    0.0000       414\n",
      "          CD19+ B     0.0000    0.0000    0.0000       284\n",
      "         CD56+ NK     0.0000    0.0000    0.0000       236\n",
      "              NKT     0.2400    0.0175    0.0327       342\n",
      "       eosinophil     0.0503    1.0000    0.0958       523\n",
      "\n",
      "         accuracy                         0.0507     10426\n",
      "        macro avg     0.0323    0.1131    0.0143     10426\n",
      "     weighted avg     0.0104    0.0507    0.0059     10426\n",
      "\n",
      "    unknown   CD4+ T   CD8+ T   CD15+ neutrophil   CD14+ monocyte   CD19+ B   CD56+ NK       NKT   eosinophil\n",
      "0       0.0      0.0      0.0                0.0              0.0       0.0        0.0  0.032698     0.095752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alexa\\anaconda3\\envs\\interai\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Alexa\\anaconda3\\envs\\interai\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Alexa\\anaconda3\\envs\\interai\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"Start validation\")\n",
    "for train_indx, test_indx in rkf_search.split(X, y):\n",
    "    train_dataset = Dataset_Generator(h5_file, train_indx, reshape_size=64, transform=transform,\n",
    "                                      only_channels=only_channels, only_classes=only_classes)\n",
    "    trainloader = DataLoader(train_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False,\n",
    "                             num_workers=num_workers)\n",
    "    statistics = get_statistics(trainloader, only_channels)\n",
    "    train_dataset = Dataset_Generator(h5_file, train_indx, reshape_size=64, transform=transform,\n",
    "                                      means=statistics[\"mean\"].div_(len(trainloader)),\n",
    "                                      stds=statistics[\"std\"].div_(len(trainloader)), only_channels=only_channels,\n",
    "                                      only_classes=only_classes)\n",
    "    test_dataset = Dataset_Generator(h5_file, test_indx, reshape_size=64,\n",
    "                                     means=statistics[\"mean\"].div_(len(trainloader)),\n",
    "                                     stds=statistics[\"std\"].div_(len(trainloader)), only_channels=only_channels,\n",
    "                                     only_classes=only_classes)\n",
    "    trainloader = DataLoader(train_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False,\n",
    "                             num_workers=num_workers)\n",
    "    testloader = DataLoader(test_dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=False,\n",
    "                            num_workers=num_workers)\n",
    "    model = resnet18(pretrained=True)\n",
    "\n",
    "    # loading the imagenet weights in case it is possible\n",
    "    if num_channels != 3:\n",
    "        model.conv1 = nn.Conv2d(num_channels, 64, kernel_size=(7, 7),\n",
    "                                    stride=(2, 2), padding=(3, 3), bias=False)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_ftrs, num_classes)\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "    for epoch in range(n_epochs):\n",
    "        running_loss = 0.0\n",
    "        print('epoch%d' % epoch)\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            indx = (data[\"object_number\"] != -1).reshape(-1)\n",
    "            if indx.sum() > 0:\n",
    "                inputs, labels = data[\"image\"][indx], data[\"label\"][indx]\n",
    "\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                inputs = inputs.float()\n",
    "                labels = labels.reshape(-1)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward + backward + optimize\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "                loss = criterion(outputs, F.one_hot(labels.long(), num_classes).type_as(outputs))\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "            if i % 500 == 499:  # print every 2000 mini-batches\n",
    "                print('[%d, %5d] training loss: %.8f' % (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    y_true = list()\n",
    "    y_pred = list()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            indx = (data[\"object_number\"] != -1).reshape(-1)\n",
    "            if indx.sum() > 0:\n",
    "                inputs, labels = data[\"image\"][indx], data[\"label\"][indx]\n",
    "\n",
    "                inputs, labels = inputs.to(device), labels.to(device)     \n",
    "                inputs = inputs.float()\n",
    "                labels = labels.reshape(-1)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                pred = outputs.argmax(dim=1)\n",
    "                _ , predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (labels.reshape(-1) == predicted).sum().item()\n",
    "                for i in range(len(pred)):\n",
    "                    y_true.append(labels[i].item())\n",
    "                    y_pred.append(pred[i].item())\n",
    "\n",
    "    print('Accuracy of the network on the %d test images: %d %%' % (len(test_dataset),\n",
    "        100 * correct / total))\n",
    "    print(classification_report(y_true, y_pred, target_names=class_names, digits=4))\n",
    "    f1_score_original = f1_score(y_true, y_pred, average=None, labels=np.arange(num_classes))\n",
    "    df = pd.DataFrame(np.atleast_2d(f1_score_original), columns=class_names)\n",
    "    print(df.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e2a347-290e-42ba-96b6-979320023dd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "interai",
   "language": "python",
   "name": "interai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
